{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# model = YOLO(r'D:\\New_Fourth_Year\\projectDesignGit\\Yolov8_v2-final\\Yolov8_v4_30epochs\\yolov8n.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20  Python-3.8.18 torch-2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\ultralytics\\yolo\\cfg\\__init__.py\", line 249, in entrypoint\n",
      "    getattr(model, mode)(verbose=True, **overrides)\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 146, in predict\n",
      "    return self.predictor(source=source, stream=stream, verbose=verbose)\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 158, in __call__\n",
      "    return list(self.stream_inference(source, model, verbose))  # merge list of Result into one\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 199, in stream_inference\n",
      "    self.results = self.postprocess(preds, im, im0s, self.classes)\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\ultralytics\\yolo\\v8\\detect\\predict.py\", line 24, in postprocess\n",
      "    preds = ops.non_max_suppression(preds,\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 240, in non_max_suppression\n",
      "    i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\torchvision\\ops\\boxes.py\", line 41, in nms\n",
      "    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\n",
      "  File \"C:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\torch\\_ops.py\", line 692, in __call__\n",
      "    return self._op(*args, **kwargs or {})\n",
      "NotImplementedError: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n",
      "\n",
      "CPU: registered at C:\\Jenkins\\Miniconda3\\conda-bld\\torchvision_1695412691308\\work\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\n",
      "QuantizedCPU: registered at C:\\Jenkins\\Miniconda3\\conda-bld\\torchvision_1695412691308\\work\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\n",
      "BackendSelect: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\n",
      "Python: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:153 [backend fallback]\n",
      "FuncTorchDynamicLayerBackMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:498 [backend fallback]\n",
      "Functionalize: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:290 [backend fallback]\n",
      "Named: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\n",
      "Conjugate: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\n",
      "Negative: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\n",
      "ZeroTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\n",
      "ADInplaceOrView: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:86 [backend fallback]\n",
      "AutogradOther: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:53 [backend fallback]\n",
      "AutogradCPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:57 [backend fallback]\n",
      "AutogradCUDA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:65 [backend fallback]\n",
      "AutogradXLA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:69 [backend fallback]\n",
      "AutogradMPS: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:77 [backend fallback]\n",
      "AutogradXPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:61 [backend fallback]\n",
      "AutogradHPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:90 [backend fallback]\n",
      "AutogradLazy: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:73 [backend fallback]\n",
      "AutogradMeta: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:81 [backend fallback]\n",
      "Tracer: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\TraceTypeManual.cpp:296 [backend fallback]\n",
      "AutocastCPU: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\autocast_mode.cpp:382 [backend fallback]\n",
      "AutocastCUDA: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\autocast_mode.cpp:249 [backend fallback]\n",
      "FuncTorchBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:710 [backend fallback]\n",
      "FuncTorchVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\n",
      "Batched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\n",
      "VmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\n",
      "FuncTorchGradWrapper: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:203 [backend fallback]\n",
      "PythonTLSSnapshot: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:161 [backend fallback]\n",
      "FuncTorchDynamicLayerFrontMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:494 [backend fallback]\n",
      "PreDispatch: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:165 [backend fallback]\n",
      "PythonDispatcher: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:157 [backend fallback]\n",
      "\n",
      "Sentry is attempting to send 2 pending events\n",
      "Waiting up to 2 seconds\n",
      "Press Ctrl-Break to quit\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=r'D:\\New_Fourth_Year\\projectDesignGit\\Yolov8_v2-final\\Yolov8_v4_30epochs\\runs-20231204T034822Z-001\\runs\\detect\\train\\weights\\best.pt' source=r'D:\\New_Fourth_Year\\projectDesignGit\\bandedChlorosis.jpg'  show=True imgsz=800 name=yolov8n_v8_50e_infer800 hide_labels=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20  Python-3.8.18 torch-2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(r'Yolov8_v2-final\\PD-2-8\\test\\images\\bandedChlorosis-193-_jpg.rf.24126856f40b27e98cd1dbfa4fe14192.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: malformed \\N character escape (1483349854.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    model = YOLO('D:\\New_Fourth_Year\\projectDesignGit\\Yolov8_v2-final\\Yolov8_v3\\yolov8n.pt')  # load a pretrained YOLOv8n detection model\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: malformed \\N character escape\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('D:\\New_Fourth_Year\\projectDesignGit\\Yolov8_v2-final\\Yolov8_v3\\yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
    "model.train(data='D:\\New_Fourth_Year\\projectDesignGit\\Yolov8_v2-final\\PD-2-8\\train', epochs=3)  # train the model\n",
    "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'YOLO' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\New_Fourth_Year\\projectDesignGit\\usingYolov8.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/New_Fourth_Year/projectDesignGit/usingYolov8.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49msummary()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'YOLO' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 640 # Size of the input image\n",
    "n_classes = 80    # Number of object classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\n            'Results' object has no attribute 'names'. Valid 'Results' object attributes and properties are:\n\n            Attributes:\n                boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n                masks (Masks, optional): A Masks object containing the detection masks.\n                probs (torch.Tensor, optional): A tensor containing the detection class probabilities.\n                orig_shape (tuple, optional): Original image size.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\New_Fourth_Year\\projectDesignGit\\usingYolov8.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/New_Fourth_Year/projectDesignGit/usingYolov8.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(result\u001b[39m.\u001b[39;49mnames)\n",
      "File \u001b[1;32mc:\\Users\\Jerico\\anaconda3\\envs\\useGPU\\lib\\site-packages\\ultralytics\\yolo\\engine\\results.py:103\u001b[0m, in \u001b[0;36mResults.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attr):\n\u001b[0;32m    102\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m--> 103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[39m        \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Valid \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object attributes and properties are:\u001b[39m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39m        Attributes:\u001b[39m\n\u001b[0;32m    107\u001b[0m \u001b[39m            boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\u001b[39m\n\u001b[0;32m    108\u001b[0m \u001b[39m            masks (Masks, optional): A Masks object containing the detection masks.\u001b[39m\n\u001b[0;32m    109\u001b[0m \u001b[39m            probs (torch.Tensor, optional): A tensor containing the detection class probabilities.\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[39m            orig_shape (tuple, optional): Original image size.\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: \n            'Results' object has no attribute 'names'. Valid 'Results' object attributes and properties are:\n\n            Attributes:\n                boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n                masks (Masks, optional): A Masks object containing the detection masks.\n                probs (torch.Tensor, optional): A tensor containing the detection class probabilities.\n                orig_shape (tuple, optional): Original image size.\n            "
     ]
    }
   ],
   "source": [
    "print(result.names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "useGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
