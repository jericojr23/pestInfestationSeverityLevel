{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_giw5WpJ1F62"
      },
      "source": [
        "# **Preprocessing the Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMHMDb5hDoK3",
        "outputId": "1ade0bbe-e573-4677-aa03-0e4c42cf752f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AehgsDqgz6fn",
        "outputId": "b2cb7d30-88e4-4cff-b2cc-cb07baa4ec04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: /content/data/DATASET/Training Samples/8/18758.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18764.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18780.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18787.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18809.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18814.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18840.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18853.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18863.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18875.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18876.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1889.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18895.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18909.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18910.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18924.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18937.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18946.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18947.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18954.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18963.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1897.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/18976.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1898.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18995.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/18996.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1900.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19006.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19012.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19037.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19038.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19045.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19047.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1905.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19053.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19071.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19074.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19111.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19129.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/19137.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19142.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19144.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19153.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19160.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19174.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19175.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/19177.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19182.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19188.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/192.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19204.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19224.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1923.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19231.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19238.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19240.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1925.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19255.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19261.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19267.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1927.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19284.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19295.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19299.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19325.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19331.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19340.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19347.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19348.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19369.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19379.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19382.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19384.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19392.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19397.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19420.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19422.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19459.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19466.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19475.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19476.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/19484.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19501.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19540.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19544.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19558.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19564.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19572.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19576.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19580.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19588.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19610.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19618.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19619.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19633.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/19649.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19661.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19665.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19677.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19684.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19688.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19692.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19696.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19703.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19705.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19715.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19719.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19754.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19757.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19760.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19767.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19768.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19779.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19783.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1980.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19806.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19813.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19819.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19824.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19829.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19854.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19859.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/1987.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19881.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19891.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19898.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/199.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1991.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1992.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19925.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19928.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19935.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/1994.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19976.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/19988.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20019.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20033.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20043.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20049.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20082.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20084.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20092.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20093.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20096.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20101.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20115.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2012.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20126.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2013.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20140.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20171.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20185.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20188.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/202.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20213.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20218.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20250.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20263.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2031.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20311.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20315.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20322.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20335.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20348.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2036.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20361.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20362.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2039.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20392.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20399.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20403.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20404.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/20412.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20413.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20435.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20442.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20452.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20471.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20480.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20482.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20504.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20510.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20520.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20523.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2055.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20556.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2056.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20563.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20578.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2058.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20592.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20593.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20615.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20638.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20640.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20643.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20665.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20666.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20685.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20696.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20718.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20719.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2073.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20735.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20736.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20743.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20747.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2075.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20750.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20755.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20757.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20760.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20773.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20787.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20793.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20806.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20843.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20851.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20864.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20866.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20875.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20879.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20880.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20885.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20890.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20900.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20909.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20910.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20915.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20934.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20943.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20950.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20955.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20976.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2098.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20984.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20991.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/20996.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21000.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21001.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21011.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21016.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21018.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21027.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21030.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21035.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21040.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21042.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21058.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21059.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2107.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21071.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21072.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21097.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21107.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21114.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21119.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21124.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2115.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21158.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21168.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21198.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21199.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/212.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21202.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21238.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21244.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21245.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21296.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21300.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21315.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21323.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21325.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21327.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21329.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21330.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21336.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21373.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21377.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21384.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21405.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2141.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21428.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21431.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21437.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21444.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21449.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21458.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21477.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21485.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/21487.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21490.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21518.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21522.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21532.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21544.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21550.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21551.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21557.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2157.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21578.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21580.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21602.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2161.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21614.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21621.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21623.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21629.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21630.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21647.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21651.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2166.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21667.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21674.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21681.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21695.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21702.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21716.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21717.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21719.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/21720.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21736.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21769.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21770.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21776.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21777.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2178.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21784.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21807.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21821.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21822.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21844.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21846.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21855.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21861.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21876.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21888.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21896.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21902.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21904.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21912.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21920.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21927.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21949.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/21962.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21970.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21971.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/21991.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22000.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22001.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22007.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22011.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22015.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22023.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22054.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22055.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22060.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22068.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22079.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2208.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22094.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22098.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22099.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2210.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22121.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22130.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22131.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22132.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22136.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22144.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22147.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22152.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22156.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22163.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22167.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22168.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22170.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22171.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22178.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22184.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22187.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22199.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22206.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22210.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22223.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22239.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22241.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22244.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2225.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22254.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22259.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22260.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22261.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22275.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22287.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22297.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22300.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2232.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22352.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22358.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22360.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22367.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22375.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22386.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22388.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22392.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2240.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22400.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22404.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22413.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22414.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22424.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22426.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2246.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22480.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22494.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22499.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/225.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2250.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22515.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22528.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2254.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22544.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22551.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22567.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2258.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22582.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22583.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22598.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22599.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22618.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22630.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22632.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2264.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22662.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2267.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22671.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22677.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22679.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22682.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22701.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22712.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22717.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22721.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22728.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22730.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22731.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22762.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/2280.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22800.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22807.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2281.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22811.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22819.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22828.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22835.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22847.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22856.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22866.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22871.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22875.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22878.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22883.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22887.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/22891.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22910.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22918.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22923.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2294.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22971.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22985.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/22996.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23004.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2302.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23022.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23039.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23047.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23048.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23051.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/23053.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23055.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23069.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23084.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23086.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23088.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23089.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23096.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23103.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23120.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23122.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23135.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23145.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23160.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23161.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23176.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23182.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23185.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2320.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23203.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23214.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23215.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23237.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2324.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23241.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23242.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23248.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23254.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23263.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23267.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23277.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23281.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/2329.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23311.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/23330.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23332.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23336.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23359.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23360.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23372.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23392.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23434.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23451.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23476.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/23504.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23514.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23515.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23519.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23526.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2353.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23538.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23539.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23580.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23582.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23596.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23599.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23602.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23616.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23628.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23653.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23659.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2367.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23672.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23676.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/237.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23707.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23709.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23723.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2374.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23745.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23754.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23758.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23775.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23809.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23811.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23816.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23824.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23840.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23863.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23875.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23885.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23889.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23903.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23935.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2395.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23962.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2397.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23974.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23985.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23991.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23993.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/23999.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24005.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24007.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/24019.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24031.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/24041.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24051.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24067.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24072.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24101.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/24110.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/24115.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24118.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2417.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24171.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24181.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24193.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/242.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24202.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24219.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24225.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2423.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24258.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24260.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24276.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2428.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24283.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24294.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24305.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24328.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2433.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24364.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24399.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24411.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24436.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24443.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24448.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24449.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24498.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24502.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24522.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24527.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24530.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24542.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24555.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24564.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24566.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24571.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24577.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2458.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/24586.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24589.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24595.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24596.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24603.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24609.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24625.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2463.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24632.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24634.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24641.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/24643.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24647.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24650.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24654.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24658.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2467.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24673.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24692.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24698.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24700.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24718.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2472.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24720.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24735.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24737.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2474.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24740.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24744.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24756.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24757.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24765.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24770.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24777.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24785.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24787.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24796.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24800.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24805.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24812.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24815.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24820.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24822.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2483.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24830.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24837.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24839.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24865.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2488.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24882.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24885.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24889.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2489.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2490.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24906.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24920.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24924.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24943.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24957.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24960.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24963.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24975.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24978.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24995.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/24997.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25003.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25022.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25026.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25028.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/25034.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25057.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25058.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25084.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25108.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/25113.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25126.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25134.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25144.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25149.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25161.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25197.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25231.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/25243.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25255.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25278.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25281.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25317.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25328.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25345.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25349.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25362.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25367.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25397.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2542.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/25431.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25449.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25461.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25468.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25490.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25501.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25513.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25515.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25536.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25540.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25541.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2555.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25550.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25553.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25564.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25565.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2557.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25578.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25579.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25595.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25597.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25607.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25609.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25612.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25614.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25630.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25634.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25636.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25638.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25641.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25642.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25648.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25663.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25705.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25712.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25718.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25727.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25741.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25758.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/2577.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25779.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25790.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25829.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/25850.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25855.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25874.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25879.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25898.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25899.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25921.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25940.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25942.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25944.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25969.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25973.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25978.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25985.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/25988.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26016.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2602.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26033.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26035.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26041.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26061.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26078.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2611.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26127.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26128.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26133.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26134.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26143.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2615.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26151.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26166.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26167.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26168.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26176.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/26189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2619.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26190.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26199.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26200.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26201.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26202.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26221.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2623.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26240.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26249.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26254.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26260.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26267.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26300.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26315.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26321.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26349.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26357.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26372.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26381.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26382.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26386.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26405.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/2641.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26410.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26413.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/26419.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/26430.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26432.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26436.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26439.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/2647.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26472.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26477.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26485.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2649.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26494.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26500.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/26505.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26508.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26528.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26537.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26540.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26545.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26560.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26566.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26580.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26592.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26608.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26610.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2663.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26636.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/26659.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26661.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26667.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26671.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26672.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26685.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2669.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26729.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26731.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26737.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26742.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26743.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26748.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26755.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26761.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26771.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26774.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26792.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26801.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/26805.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26820.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26821.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26829.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26853.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26856.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26857.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26860.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26866.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26890.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26911.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26913.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26919.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26921.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26947.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26948.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26950.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26957.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26961.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26969.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26985.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/26996.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27019.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27021.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27040.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27049.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27058.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27067.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27069.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27072.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27075.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27089.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2709.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27091.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27095.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27104.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27112.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27113.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27119.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2714.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27143.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27160.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27179.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27203.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27206.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27208.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/27215.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27220.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27230.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27250.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/27265.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27270.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27271.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/27278.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2729.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2730.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27310.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27314.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27327.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27330.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27342.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2735.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27361.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27376.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27377.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27395.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27439.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27440.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27464.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27465.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/27471.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27474.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2750.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27504.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27507.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27511.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27515.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27524.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27534.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27550.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27552.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27560.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27568.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27579.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27585.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27587.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27601.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27607.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27608.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27609.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27637.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27661.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/27674.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27678.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27681.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27683.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27701.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27708.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27709.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27723.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27739.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27746.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27759.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27773.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27776.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27784.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/278.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27827.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27834.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2785.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27859.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27868.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27869.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27871.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27896.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27911.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27944.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2795.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27962.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27969.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27977.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27982.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/27989.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28000.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28002.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28019.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/28020.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/28039.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2806.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2807.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2809.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28092.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28099.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2812.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28125.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2813.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28140.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/28142.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28168.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28173.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2818.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28184.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2819.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28197.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/282.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2820.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28224.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28230.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28239.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28245.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28250.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/2826.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28274.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28276.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28282.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2829.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28290.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2830.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28316.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28320.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28327.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28331.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28334.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28335.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28349.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28352.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28369.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28372.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28373.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28388.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28399.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28402.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28414.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28436.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28438.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28451.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28456.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28459.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28467.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2848.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28492.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28528.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28535.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28538.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28540.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28542.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28552.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28553.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28577.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28582.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28584.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28590.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28592.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28605.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28615.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28616.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2863.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28631.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28636.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28641.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28642.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28655.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28658.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/28706.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28708.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28711.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28741.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28742.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28754.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28763.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28770.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28773.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28783.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28787.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/28791.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/28792.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28800.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/28802.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28814.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28818.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28827.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2884.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28855.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28899.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28910.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28932.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28959.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28971.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/28994.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/28998.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2902.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29023.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29025.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29029.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29036.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29038.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29045.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29047.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29060.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29063.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29064.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2908.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29088.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2909.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29091.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29095.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/291.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29103.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29104.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/29105.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29133.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29141.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29145.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/2915.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29150.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2917.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29185.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29197.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29213.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29222.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29225.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29226.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2923.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29230.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/29237.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29238.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29242.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29243.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/29251.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/29259.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29268.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2927.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29286.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29292.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29304.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29317.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29332.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/29351.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29372.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29380.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29382.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29390.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29393.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29404.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29405.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2941.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29432.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/29481.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29487.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2950.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29500.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29515.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29524.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2953.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29537.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29542.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29548.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29558.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29563.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29565.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29572.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29574.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2958.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29585.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29617.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29619.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29622.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29625.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29642.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2968.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29680.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29683.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29702.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29710.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29711.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29718.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29761.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29770.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29796.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2983.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29831.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29834.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29837.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29847.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29891.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29895.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29898.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/299.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29908.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29912.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29915.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29919.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29930.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29947.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29954.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/29957.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29958.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/2996.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/29968.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29974.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29976.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29978.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/29982.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/30008.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3001.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30011.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30016.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3002.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30022.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30026.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30028.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30039.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30056.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/30061.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30081.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30082.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30085.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30099.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3010.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30107.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30110.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30119.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30120.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30127.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30138.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30152.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30156.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30159.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30160.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30171.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30193.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30198.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30202.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/30223.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30237.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30241.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30242.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30248.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30284.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3029.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30306.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30307.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/3031.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30314.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30346.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30348.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30358.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30360.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30361.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30365.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30372.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30384.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30396.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30397.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30398.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3040.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30406.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30420.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30451.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30458.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3046.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30471.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30487.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30499.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30503.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3051.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30520.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30527.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30532.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30541.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30542.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30544.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30555.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30574.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30600.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30604.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30621.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30623.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30624.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30634.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30639.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30641.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30652.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30655.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30660.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/30671.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3068.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30687.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30699.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30703.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30723.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/30725.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30726.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30728.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30729.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30733.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30743.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30775.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30783.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/30788.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3080.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30826.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30843.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30844.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30849.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30850.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30872.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30884.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30887.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30895.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30919.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/30943.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31001.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31004.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31013.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31032.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31037.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31042.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31049.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31051.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31059.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31062.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31064.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31076.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31084.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31109.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31119.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31138.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31146.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31156.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/31159.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31167.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31169.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31171.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31198.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31245.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3126.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31279.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31337.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3134.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/31348.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31351.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3136.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31361.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31364.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31383.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31393.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31394.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31399.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31409.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3141.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31416.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31427.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31471.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31474.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31478.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31480.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31481.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31495.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/315.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/31500.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31503.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31530.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31534.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31536.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31545.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31563.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31565.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3158.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31587.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31613.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31615.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3163.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31649.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31651.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31655.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31662.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31678.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31685.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31701.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31710.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31716.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31718.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31743.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/31750.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31751.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31757.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3176.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31766.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31771.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31795.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/31812.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/31824.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31829.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31831.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31846.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31864.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31866.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31869.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31876.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31881.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31893.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31894.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31900.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31928.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31938.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31940.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31942.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3195.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31954.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31976.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3198.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/31986.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31987.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31989.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3199.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/31998.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32005.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32006.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32020.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32023.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32037.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3204.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32047.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32051.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32055.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3206.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/32060.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32067.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32070.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32072.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3208.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32082.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/32085.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32103.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32112.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32116.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3212.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32135.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32150.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32152.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32165.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32179.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3218.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32197.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32212.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32214.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3222.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32222.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32229.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32249.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3229.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32296.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32304.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32306.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32318.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/32354.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32370.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32376.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32385.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32400.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3241.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32427.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32451.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32463.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32465.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32467.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32472.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32529.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32536.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32566.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32570.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32617.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/32618.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32631.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32635.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32638.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32643.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32660.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32671.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/32679.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32691.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32702.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32721.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32729.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32736.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32739.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32750.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32756.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/32778.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3278.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32795.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32796.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32800.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3284.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32849.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32850.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32851.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32887.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32890.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32901.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32908.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3291.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/32912.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32922.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32941.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32990.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/32995.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33012.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33013.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33017.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33027.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3303.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33036.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3304.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33056.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33059.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33062.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33065.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33089.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33096.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33103.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33111.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33118.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33121.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33138.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33160.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33165.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33167.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33169.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3317.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33183.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33192.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33210.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33235.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33244.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33255.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33261.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33270.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33276.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/33278.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33285.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33300.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33310.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33319.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33332.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33339.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3334.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33341.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33343.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33350.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33360.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33367.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33376.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33379.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33382.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3339.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33390.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33397.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/334.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33416.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33425.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33430.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33434.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33451.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33456.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33493.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3351.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33523.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33565.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33570.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33574.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33584.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33590.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33606.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33612.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33624.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33632.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33635.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3365.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33683.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33699.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33714.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3372.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33746.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33748.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33772.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33792.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33793.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33795.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33814.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33831.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33840.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33849.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33852.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33853.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33870.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33879.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33881.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33895.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33899.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33908.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33911.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33922.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33926.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33930.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33948.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33952.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33957.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33961.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33969.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3397.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/33983.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34006.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34011.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34012.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34026.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34028.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34041.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34044.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34059.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34064.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34065.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34076.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34080.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34083.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34098.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3411.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34118.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34122.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34123.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34126.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34141.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34153.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34155.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34183.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34188.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34190.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34191.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34193.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34201.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34211.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34216.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34232.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34240.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34242.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34243.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34257.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34273.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34275.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34278.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34281.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34283.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34290.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34294.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34311.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34314.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3434.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34349.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34352.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34364.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34372.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34383.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34387.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34390.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/34392.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/34443.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34458.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3446.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34465.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3447.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34473.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34474.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34483.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34491.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34514.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34521.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34524.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34540.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34542.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34555.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/34567.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34569.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34610.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34620.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34622.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34640.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34645.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/34647.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/34656.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34658.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34673.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34675.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34678.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34682.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34683.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34689.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34700.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34715.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34716.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34721.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34729.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/34751.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34755.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/34762.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34767.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34776.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3478.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34781.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34790.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34792.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34794.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/34796.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34801.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34811.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34815.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34822.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34823.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34825.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34827.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3483.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34848.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34869.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/34880.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34886.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34890.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34893.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34900.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34912.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34917.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34919.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34920.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34951.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/34977.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35038.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35052.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3506.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35067.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35069.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35072.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3510.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35103.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35114.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35122.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35126.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35129.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35147.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35155.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35165.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35209.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35221.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35260.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35281.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35292.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35297.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35305.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35309.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35324.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35326.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35329.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35334.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3534.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35342.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35344.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35352.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35355.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35368.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35384.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35387.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35390.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35391.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35420.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/35423.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35424.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35428.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35443.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35455.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35463.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35468.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35474.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35478.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3548.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35489.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35507.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35519.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35537.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35552.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35565.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35572.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35583.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35612.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3562.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35653.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35659.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35666.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35671.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3568.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35680.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35682.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35693.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/35713.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35714.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35731.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35735.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3575.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35760.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35774.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35784.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35791.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35799.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/358.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3580.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35814.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3582.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35821.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35836.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35840.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35841.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35859.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35878.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35890.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35894.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35900.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35912.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35917.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35922.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3593.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/35932.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35945.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35958.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/35965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/360.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36017.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36025.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36030.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36037.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36064.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36077.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/36081.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36094.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36108.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3612.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36125.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36134.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36136.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36150.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36158.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36171.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36180.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36187.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36195.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3620.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36220.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36221.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36230.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/36264.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36275.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36282.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36291.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36296.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/36298.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36302.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36355.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36360.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36365.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36378.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36415.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36462.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36466.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3648.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36480.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36524.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3654.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36541.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36544.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36549.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36575.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36588.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/366.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36600.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36604.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36606.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36621.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36624.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3666.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36660.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36661.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36668.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36697.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36704.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36723.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36736.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36761.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36770.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36784.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36790.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/36794.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36797.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36804.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36805.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36806.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36812.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/36848.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36850.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/36854.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36857.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36861.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36872.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36874.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36875.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36879.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36880.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36884.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36889.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36943.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/36947.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36948.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36952.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36960.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/36973.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36980.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36985.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/36996.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37003.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37004.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37015.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3702.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3703.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37043.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37053.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37062.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37093.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3711.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37126.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37155.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37163.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37176.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37181.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37183.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37210.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37269.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37297.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3730.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37313.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37317.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37323.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/37326.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37333.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37338.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37347.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3736.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37370.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37383.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37391.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37401.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37411.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37430.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37435.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37439.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37444.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3745.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37465.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3749.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3750.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/37506.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37507.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37532.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37533.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37551.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37561.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37567.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37574.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37579.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37580.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37598.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37608.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37609.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/3762.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37620.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37624.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37626.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37627.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37628.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37633.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37651.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37662.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37663.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37675.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3768.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37694.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37710.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37712.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37718.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37726.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37730.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37745.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37776.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37780.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37838.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37846.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37854.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37855.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37860.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37870.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37876.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37878.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3790.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37923.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37928.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37939.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3794.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37954.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3796.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37963.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37966.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37969.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37983.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/37996.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/380.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38002.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38020.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38021.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38034.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38038.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38043.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38044.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/38062.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3807.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38075.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38076.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38080.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38084.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/38089.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38090.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38098.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38105.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38112.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38127.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3814.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38140.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38144.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38145.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38148.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38149.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38172.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38177.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38203.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38233.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38237.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/38240.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38243.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38251.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38255.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/38257.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38259.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38263.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38271.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38273.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/38304.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38305.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38317.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38327.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38328.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38330.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38333.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/38346.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38359.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38366.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38367.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38378.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38381.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38387.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38396.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38397.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/38405.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38411.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38424.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38425.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38431.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38434.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38439.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38457.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38514.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38515.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38520.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38522.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38532.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3856.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38561.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38562.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38569.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38584.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3861.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38615.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38629.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38630.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38678.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38690.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38699.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38705.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38711.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38754.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38765.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38767.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3877.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38772.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/38789.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38793.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38796.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38807.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3881.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38810.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38817.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3882.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38823.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38827.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38829.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3884.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38843.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38846.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38850.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/38859.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38864.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38890.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38895.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38901.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38912.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38926.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38930.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38939.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38943.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38955.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38958.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38966.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38978.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38981.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/38998.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/39006.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39007.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39016.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39019.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39031.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39054.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39076.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39094.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39105.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/39107.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/39111.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39118.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39129.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39131.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/39146.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39151.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39165.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39168.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39173.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39184.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39190.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39194.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/39200.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39209.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39210.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39221.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39222.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39240.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39252.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39256.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39258.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39264.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39267.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39281.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39307.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39313.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39324.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39329.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3933.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39331.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39366.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39378.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39382.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39384.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39396.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39398.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39407.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39412.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39423.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/39428.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3943.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39430.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39431.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39444.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39449.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39475.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39496.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/395.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39514.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/39527.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39529.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39533.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39544.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3955.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3956.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39594.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39595.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39599.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39600.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39611.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39614.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39618.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39633.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39640.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39653.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39655.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39665.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39670.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39675.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39683.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39698.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39701.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39706.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39719.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39720.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/39760.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39764.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39766.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39775.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39781.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39787.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39789.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39793.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39794.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39801.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39803.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39806.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39827.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39830.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39834.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39854.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39856.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39861.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39867.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3987.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39871.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39881.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39898.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/399.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/3992.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39920.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39923.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39934.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39947.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39950.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39968.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39978.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/39984.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40020.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4003.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4004.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40052.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40071.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40074.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4008.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40080.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40103.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40110.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4012.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40123.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40135.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40137.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40147.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40148.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40165.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40174.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40175.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40191.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40197.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/402.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4021.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40225.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40235.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4024.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40253.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40255.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40266.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40271.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40285.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40289.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40297.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40300.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40311.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40335.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40347.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40366.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40367.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4037.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40394.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40403.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40404.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4041.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40434.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40436.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40440.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40448.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/40449.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40453.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/40458.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4046.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40465.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40467.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40468.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4048.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4049.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40510.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40514.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40528.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40557.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40562.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40565.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40578.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40592.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4060.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40601.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40602.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40607.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40634.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40637.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40659.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4067.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40673.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40685.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/40688.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40689.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40690.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/40703.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40706.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40707.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40719.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40722.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40724.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40726.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40727.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40744.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40749.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40754.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/4076.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40763.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/40777.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40810.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40815.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40820.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40823.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40844.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40848.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4088.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4091.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40917.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40920.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40934.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40949.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40957.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40959.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40977.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40988.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40989.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40993.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40994.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/40999.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/41001.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41002.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41010.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41036.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41048.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41057.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41081.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41084.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41107.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41110.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41126.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41137.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4114.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41148.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4115.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41156.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41160.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41172.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41193.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41195.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/412.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4120.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41200.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41205.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4121.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41220.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4123.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41231.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41238.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41244.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41249.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4125.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41251.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41257.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41267.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41295.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/413.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/41309.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41318.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41338.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41347.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/41351.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41368.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41378.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41379.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41381.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41386.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41399.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41410.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41414.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41436.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41438.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41439.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41453.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41463.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41469.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41475.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41484.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41488.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41513.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41522.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41531.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41534.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41543.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41554.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41572.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/41577.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41581.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41589.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41604.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41610.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41613.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41616.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41623.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/41632.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41654.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/41656.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41662.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41670.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41674.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41675.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/41687.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41689.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41702.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41711.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41719.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41721.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41723.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/41724.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4173.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41739.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4174.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/41740.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41742.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41744.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41757.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41777.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41788.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4179.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41796.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41800.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41808.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41815.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41820.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41827.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41831.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41841.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41843.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41853.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41888.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41889.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41898.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41909.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41912.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41915.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41919.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41937.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41951.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41955.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41962.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41968.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4197.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41972.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41976.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41987.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41991.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/41992.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42028.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42031.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42034.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42044.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42051.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42058.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42063.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42067.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42074.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42084.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/421.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42101.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42141.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42147.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42153.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4216.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42171.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4219.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/42192.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42211.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42212.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42235.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42238.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/42243.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42250.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42252.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42257.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42262.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42271.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42278.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42285.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42302.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42304.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42307.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4232.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42361.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42368.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42378.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42384.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/424.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42402.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42412.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42433.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42439.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42456.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42475.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42489.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42495.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42507.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4251.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4252.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42522.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42524.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42535.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42536.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42576.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42584.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42592.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42597.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42616.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42619.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/42651.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42659.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42669.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42682.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42701.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/42711.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/42713.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42756.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/42762.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42767.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42787.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42788.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/4279.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42793.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/42801.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4282.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42825.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42830.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42834.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42854.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4286.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42864.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4287.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42894.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42896.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42904.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42913.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42921.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42923.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42930.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42933.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42947.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4295.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42969.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42985.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/42989.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4299.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43014.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43022.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4304.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4305.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43051.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43052.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43059.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43075.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43085.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43088.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43095.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43097.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4310.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43116.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43123.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43136.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43139.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4314.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43158.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4317.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43175.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43197.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43205.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43216.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43218.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4322.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43221.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43223.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43234.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43244.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43245.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43250.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43254.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43269.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/43276.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43280.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43285.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43309.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43314.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43319.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43321.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43346.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43351.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43361.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43362.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43370.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43379.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43388.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43390.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43392.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43401.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43413.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43421.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43423.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43425.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43436.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4345.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43464.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43482.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/43484.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43501.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/43507.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43542.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43544.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43550.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43557.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43558.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43565.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/43571.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43573.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/43589.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43602.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43610.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43614.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43622.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43637.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43638.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43642.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43649.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4365.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43650.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43651.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43658.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43661.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43670.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4368.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43681.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43690.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43719.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43721.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43734.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43749.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43751.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43754.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43757.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43762.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43764.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43769.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/43770.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43778.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43794.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43797.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/4382.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43820.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43825.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43840.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43844.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43845.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43850.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43859.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43870.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43895.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43899.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43919.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43928.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43966.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43978.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43985.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43988.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/43997.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44013.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44014.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4402.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44065.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/441.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44101.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44119.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44120.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44125.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4413.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44144.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44148.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44166.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44167.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44168.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44171.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44186.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44196.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44201.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44202.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44208.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4421.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4426.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44260.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44267.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/44270.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44293.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44294.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44295.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44303.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44307.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44322.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44325.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44326.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44333.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44337.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44338.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44341.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44344.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44354.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4436.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44363.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44375.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44395.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44404.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44407.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44411.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44413.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44420.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44429.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44437.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4444.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44445.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44449.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44450.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44451.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44455.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4447.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44484.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44509.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44514.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44523.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44524.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44552.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/44566.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44586.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44597.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44634.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44636.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44685.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44690.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44699.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44713.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44714.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44723.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44724.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44736.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44738.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44739.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44763.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44771.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44773.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44782.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44792.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44815.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44827.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/44831.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44836.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44844.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44871.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44874.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44885.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44889.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44894.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44900.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44901.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/44902.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44905.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44925.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44935.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44938.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44946.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44952.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4496.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/44964.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44974.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/44978.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45001.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45008.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/45032.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4504.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45057.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45069.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45079.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45084.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45087.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45092.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45114.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45115.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45128.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45137.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45145.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45150.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45152.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45167.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45186.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/4519.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45205.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45209.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45210.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45216.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45226.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45238.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45265.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4528.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45281.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45292.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45297.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45299.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45305.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45318.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45320.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45322.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45329.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45351.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45354.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45378.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45379.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45388.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45400.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45402.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45404.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45424.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45437.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45449.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45477.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45487.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45491.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45496.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45520.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45542.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45543.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45544.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45545.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45559.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45574.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45589.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4559.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45602.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45603.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45606.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45607.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45611.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45613.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45619.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45621.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45626.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45630.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45632.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45642.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45651.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45652.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4567.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45674.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45676.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45677.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4568.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45686.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45706.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45712.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45714.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45728.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45748.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4575.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45778.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45784.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45791.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45802.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45817.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45826.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45841.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45846.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45847.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45858.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45863.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45868.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45914.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45916.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45926.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/45934.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4594.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45941.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4595.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45954.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45964.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45972.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45973.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45974.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45977.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45982.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/45998.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46003.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46023.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46025.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46054.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46057.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46086.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46088.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46094.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46099.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46103.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46104.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46121.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46138.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46142.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46154.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46168.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/46173.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46180.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46199.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46203.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46211.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46249.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46262.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46266.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46277.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46283.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46293.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/463.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46307.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46308.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/46309.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4632.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/46350.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46355.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46358.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4637.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46376.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46382.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4639.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/46401.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46404.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46410.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46414.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46424.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46435.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46437.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46450.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46457.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4649.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46501.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46516.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4652.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46533.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46534.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46543.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4656.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46575.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4659.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46593.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46597.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46600.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46611.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46613.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4662.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46625.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4663.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/46633.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46642.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46652.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46675.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46682.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/46683.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46699.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46755.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46758.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46785.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46801.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46812.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46815.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/46821.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46822.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46826.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46828.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46838.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46856.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46858.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/46871.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/4688.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46893.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46896.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/46897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46910.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46911.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46918.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46923.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46963.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46971.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/46973.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4701.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47010.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47022.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47035.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47038.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4707.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47072.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47079.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47080.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47082.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47091.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47098.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/47113.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47118.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4713.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47133.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47158.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4716.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47169.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47195.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47196.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47200.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47203.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47207.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47211.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47218.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47242.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47258.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47271.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/47281.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47298.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/473.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47314.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47335.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4734.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47343.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47371.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47381.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47392.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47394.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47403.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47406.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47417.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47419.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/4742.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47425.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47438.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47441.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47443.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47451.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47456.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47473.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47481.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47483.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47499.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47501.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47515.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47538.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47552.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/47571.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47577.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47578.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47587.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47596.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47597.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47605.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47618.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4763.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47639.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47640.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47641.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47651.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47663.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47668.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4767.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47672.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47682.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47690.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47691.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47711.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47731.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47741.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47751.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47754.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47791.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47804.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47823.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47826.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47830.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47846.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47853.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47879.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47891.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47902.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47904.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47915.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4792.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47920.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47927.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47928.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/47952.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47953.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47954.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47957.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47971.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/47975.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48008.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48011.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48024.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48027.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48047.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48050.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48056.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48073.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48076.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48088.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48098.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48102.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48123.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48127.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48134.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48135.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48145.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48152.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48156.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48157.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/482.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48205.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48208.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/48214.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48218.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48231.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48232.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48234.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48240.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4825.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48255.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48256.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48262.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48274.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48280.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48281.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48311.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48322.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/4833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48349.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48352.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/48369.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48375.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48381.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48396.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48403.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48409.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48411.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48415.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48429.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48440.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48449.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/48475.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48482.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48487.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4849.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48490.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48496.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48518.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4852.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/48521.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4854.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48540.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48578.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48586.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4859.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48590.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48611.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/48616.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48623.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48635.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48640.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48649.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48664.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48667.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48673.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4868.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48705.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48709.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48756.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48777.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48781.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48784.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4879.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48805.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/48815.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4882.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48820.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48873.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48876.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48883.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48906.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48919.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48920.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48922.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48927.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48933.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48937.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48939.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48942.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/48943.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48949.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4898.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/48985.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4899.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49001.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49013.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49027.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49050.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49072.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49097.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49105.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49121.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49123.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49125.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49130.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/49146.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49162.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49168.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/49182.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49215.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49222.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49227.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49266.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49268.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49272.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49287.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49296.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49298.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49302.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49304.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49320.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/49323.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49326.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49333.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49350.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/49368.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49382.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49383.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49387.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/494.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4941.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49429.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49468.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49475.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49481.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49491.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49492.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49493.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49498.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49503.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49518.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49520.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49523.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49538.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49549.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49554.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49574.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/49581.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49585.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4960.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49600.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49603.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49610.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49611.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49619.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4962.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49622.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49628.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/49632.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49643.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49669.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49694.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49706.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4971.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49711.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49722.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49725.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49726.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49727.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49739.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49746.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49748.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49769.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49771.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49783.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49809.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49823.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49824.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/4983.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49835.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49850.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49856.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49862.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/49874.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49896.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49918.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49924.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49960.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49964.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/49968.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/500.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50038.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50045.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5005.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50053.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50059.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50069.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50070.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50077.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50079.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50081.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50083.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50091.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50112.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50114.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50121.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50123.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5014.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50150.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50165.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50168.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50181.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50196.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50197.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50202.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50204.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50213.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50219.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5023.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50238.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50239.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50258.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50295.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50304.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50307.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50322.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50325.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50335.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50340.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50357.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50361.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50363.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50372.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50392.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50393.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50416.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50433.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50452.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50457.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50465.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50485.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50487.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50509.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50520.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50536.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50537.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50541.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50542.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5057.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50574.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50575.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50588.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50589.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5059.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50603.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50615.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50634.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50655.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50663.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5068.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50686.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50694.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50696.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50702.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50722.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50727.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50728.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50730.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50735.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5077.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50781.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50782.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50783.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50788.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50791.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50811.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50819.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50820.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50821.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/50823.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50836.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50847.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50859.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5086.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50860.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50873.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50876.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50878.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50904.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50911.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50919.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/5092.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50920.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50927.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50939.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5094.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50949.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50975.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50981.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/50986.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5099.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51014.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51035.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51045.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51076.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51080.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51089.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51091.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51092.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51094.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51099.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51100.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5111.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51126.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51133.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51140.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/51145.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51154.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51160.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51164.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51173.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51180.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51181.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5119.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51204.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51233.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51237.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51239.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51249.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51251.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51267.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5127.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51273.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51276.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51278.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5129.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51317.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51338.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51341.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51350.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51352.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51361.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51369.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51373.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51391.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51416.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5142.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51429.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51432.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51434.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51443.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51453.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51457.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51462.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51500.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51502.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51513.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51520.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/51527.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51529.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51535.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51538.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51541.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51550.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/51562.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51600.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51625.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51635.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/51639.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51690.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5170.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51725.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51728.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51729.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5173.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51736.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51737.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51747.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51750.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51791.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51792.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51795.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51802.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51805.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51808.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51848.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51855.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51863.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51894.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51898.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51902.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51911.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51918.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/51929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51937.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51940.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51950.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51951.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51964.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51974.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51984.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51986.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/51990.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52006.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52008.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52011.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/52034.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52062.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52078.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5208.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52090.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52112.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52116.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52137.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52138.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52141.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52147.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52149.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52160.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52166.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52172.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52182.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52202.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/52215.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52216.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52234.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52239.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52246.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52250.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52282.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52289.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52296.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52304.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52314.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52349.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5235.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52358.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52364.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52391.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52401.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52407.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52413.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52418.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52423.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52426.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52428.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5243.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52439.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52459.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5246.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5247.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52472.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52495.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52500.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52501.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52519.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52529.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52565.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52566.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/5258.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52615.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5263.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52637.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52645.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52648.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52650.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5267.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52672.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52686.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52689.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/52691.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52692.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52698.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52701.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52708.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5272.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52720.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52729.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52736.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52739.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52740.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52750.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52759.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52793.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52798.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52802.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52831.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/52832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52841.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52872.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52877.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52888.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/52889.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52896.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5291.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52921.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/52944.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52982.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/52990.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53012.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53018.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53049.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53050.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53072.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53077.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53094.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/53101.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53102.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/53109.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53130.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53134.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53148.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53160.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53161.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53164.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/53182.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53185.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53187.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53189.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53190.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53197.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53201.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53209.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5321.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53214.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53217.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/53222.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53239.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53253.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53256.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53265.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53292.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53303.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53325.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53329.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53348.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5338.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53384.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5339.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53392.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53402.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53413.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53417.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53428.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5344.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53468.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53469.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53478.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53491.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53497.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53500.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53514.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53516.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53527.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53532.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/53536.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53539.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53541.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53549.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53560.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53562.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53572.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53578.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/536.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53604.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53608.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/53617.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5362.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53629.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53631.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53652.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53656.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53667.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53682.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53689.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53707.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53730.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53741.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53749.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53760.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53788.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53796.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53800.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53815.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53825.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53831.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53878.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53883.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53891.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53896.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5391.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53910.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53916.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53928.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53932.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53935.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/5395.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53952.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53957.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53963.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53966.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5397.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53978.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53979.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53988.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5399.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53994.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53995.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/53997.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5400.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54004.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54006.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54009.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54018.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54028.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54044.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/54065.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54076.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54098.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54101.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54108.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54111.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54113.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54118.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54134.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54135.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54136.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54146.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54153.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54157.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54161.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54163.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54172.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54173.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54176.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54179.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54182.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54185.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54190.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54194.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/54212.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54215.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54238.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54260.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54265.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54270.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54275.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54279.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5430.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54323.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54337.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54339.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5435.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/54382.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54393.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/5440.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54414.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54415.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54430.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54444.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54450.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54452.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54457.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54463.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54472.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5448.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54492.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54493.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54499.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54510.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54515.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54525.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54526.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54540.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54543.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54546.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5457.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54572.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54580.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54585.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/54591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54592.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54598.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54603.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5461.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54612.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54621.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54633.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54642.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54646.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54650.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54653.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54667.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54679.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54683.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54700.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54714.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54720.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54722.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54735.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54746.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54748.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54765.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54779.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54783.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54791.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5481.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54812.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54833.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/54842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54861.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54864.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54882.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5489.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54895.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/54910.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/54923.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54934.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54949.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5495.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/54956.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54965.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54967.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54968.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54969.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54987.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54988.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/5499.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54991.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/54993.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55003.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55022.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55044.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55051.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55055.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5507.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55070.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55116.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/55131.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55136.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55141.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55147.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55153.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55160.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/55161.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55171.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55179.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/55199.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/552.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5522.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55222.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55237.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55241.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55254.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55259.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55262.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55273.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55276.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55279.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55282.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5532.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55320.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55346.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55349.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55357.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55390.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55416.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55425.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55454.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55481.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55486.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55491.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55494.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55497.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55504.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55518.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55519.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55524.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55537.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55546.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55550.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/556.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55604.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55616.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55618.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55620.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55629.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55631.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55643.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55648.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55663.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55672.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55677.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55681.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/55694.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55702.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55720.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55724.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/55726.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55728.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5574.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55754.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55766.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55785.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55800.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/55801.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55808.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55855.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55858.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55873.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55915.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55921.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55933.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55949.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55960.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55968.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55971.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55976.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55986.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/55998.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56015.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56026.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56030.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56036.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56039.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5604.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56044.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56054.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56056.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56066.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56070.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56086.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56101.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56109.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56112.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56136.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/56148.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56153.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/56170.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56174.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56190.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56224.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56230.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56231.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56232.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56244.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/56255.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56259.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56285.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56288.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56296.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56307.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56316.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56334.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56348.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56353.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56354.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56377.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56383.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56391.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56392.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56412.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56427.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56428.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56439.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56446.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56460.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5647.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56470.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56472.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56473.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56475.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56478.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56479.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56490.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56512.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56515.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56517.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/56518.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56526.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56530.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56553.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56563.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56565.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56571.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56576.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56588.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56594.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/56596.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56619.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56629.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56637.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56641.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56642.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56653.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56661.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56663.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/567.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56708.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56709.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56729.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56737.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56744.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56764.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/56768.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56771.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/56773.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5678.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56791.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56793.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56794.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56798.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56818.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56819.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56826.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56834.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56838.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5684.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56849.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56859.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56865.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56866.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56879.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56880.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56883.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56885.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56887.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56913.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56918.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56922.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56941.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56942.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56944.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56952.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5697.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56979.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56993.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/56995.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5701.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57019.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57028.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57046.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57067.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57088.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5709.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/571.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57104.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57120.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57130.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57133.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57166.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57176.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57179.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57186.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57187.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/57216.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57229.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57232.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/57239.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57240.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57254.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57256.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57264.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57274.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57287.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5729.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57290.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57305.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57308.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57311.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57316.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57317.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57343.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57348.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57354.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57368.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57373.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57375.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57384.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57391.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57396.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57404.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57433.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57445.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57460.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57465.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5747.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5748.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57487.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57489.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/57500.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57505.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57510.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57514.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57524.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57534.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5754.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57542.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57561.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57593.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57595.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57596.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57618.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5762.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57627.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57629.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57633.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/57636.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57638.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57645.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57650.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57685.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57695.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57707.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57718.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57725.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57727.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57728.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57729.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5773.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57733.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57745.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57753.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57756.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57759.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57767.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5777.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57770.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5778.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57794.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57795.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/57804.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57810.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57822.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57823.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5784.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57845.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57852.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57854.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5786.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57862.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57874.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57875.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57885.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57897.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57905.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57910.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57942.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57952.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57955.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57960.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/57966.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58010.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58023.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58026.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58027.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58028.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58036.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5805.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58061.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58063.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58073.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58077.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58086.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58087.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/58090.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58101.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58105.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/58117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5814.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58142.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58173.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/58174.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58182.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58201.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58216.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58223.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58229.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58231.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58245.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58261.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/58269.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58297.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58307.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/58311.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58314.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58329.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58342.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58353.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58354.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58369.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5837.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58378.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58380.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58413.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58415.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58430.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58432.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58442.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58447.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58468.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/5849.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58498.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5850.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58506.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58510.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58544.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5856.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5857.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5860.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58604.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/58624.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58628.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58631.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58643.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58652.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58656.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58674.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58682.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58693.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58699.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58700.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58701.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58703.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58704.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58713.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58718.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58720.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58727.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58737.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58744.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58749.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58751.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58757.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58763.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58769.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5877.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58774.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58786.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58798.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/588.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58822.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58842.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58843.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5885.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58857.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5888.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58883.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58890.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5893.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58933.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58938.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58968.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/58977.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59002.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59010.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5903.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59051.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59058.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59066.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/591.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59108.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59133.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59140.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59162.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59173.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59177.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/59183.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5933.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/5934.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/5937.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/5979.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/599.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/60.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6001.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6005.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6009.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6015.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6029.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6044.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6046.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/606.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6084.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6085.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/609.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6101.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6104.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6116.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6133.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6149.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6161.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6166.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6169.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6175.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6181.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6184.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6193.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6194.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6199.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6205.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6209.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6217.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6233.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6240.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6243.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6246.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6249.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6271.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6277.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6301.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6318.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6323.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/633.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6341.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6349.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/635.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/6389.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6394.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6398.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6403.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6413.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6419.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/644.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6448.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6471.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6491.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6504.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6507.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6514.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6538.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6539.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/6541.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/6558.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6560.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6567.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6571.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6595.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6597.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6599.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6600.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6601.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6619.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6629.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6638.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/665.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6682.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/671.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6716.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6724.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6731.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6735.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/674.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/676.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6769.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6772.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6774.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6782.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6787.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6792.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6803.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6840.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6847.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/687.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6870.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6872.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6873.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6878.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/688.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6882.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6889.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6896.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/690.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6902.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6907.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6932.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6938.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6949.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/696.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6961.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6962.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6963.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6970.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/6971.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7008.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7029.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7030.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7031.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7033.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7035.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7071.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7086.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7095.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7096.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7115.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7120.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/715.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7151.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7162.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7165.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7168.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7181.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7195.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7199.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7200.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7211.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7218.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/722.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7224.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/7228.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7242.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/7251.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7264.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7271.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7277.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7281.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7296.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7312.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7319.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7327.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7341.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7344.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7350.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7353.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/736.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7364.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7369.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7380.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/74.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7402.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7426.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7467.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7478.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7490.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7503.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7504.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7509.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7545.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/755.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7551.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7552.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7557.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7572.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7578.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7589.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7595.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7597.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7609.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/761.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7617.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7624.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7627.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7647.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7649.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7652.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7653.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7659.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/7662.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7663.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7664.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7692.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7694.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7703.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7718.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7723.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7734.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7740.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7743.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/775.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7765.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7767.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7774.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7787.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7791.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7793.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7804.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7816.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7817.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7819.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7824.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7827.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7833.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7834.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7856.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7864.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7869.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/787.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7882.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7883.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7895.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7902.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7916.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7922.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7928.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7929.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/794.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/797.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/798.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7980.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/7997.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8005.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/8009.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8010.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/8011.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8012.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8016.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8022.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8063.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8070.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8072.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8079.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8088.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8091.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8099.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/811.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8117.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8127.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8141.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8159.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8167.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8170.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8172.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8185.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8192.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/821.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8220.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8230.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8239.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/8278.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8297.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8322.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/836.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8387.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/8401.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8404.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8429.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/843.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8447.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8465.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8473.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8481.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8498.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8517.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8530.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/8537.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/854.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8547.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8550.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8562.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8563.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8588.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/8599.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8602.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8619.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8622.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8630.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8633.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8636.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8653.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8654.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8657.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8658.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8660.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8683.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8685.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8698.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/8699.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8705.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8715.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8720.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8722.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8726.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8727.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8758.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8759.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/876.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8762.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8764.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8771.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8772.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8775.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8790.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8795.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8806.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8815.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8821.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8836.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8838.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8839.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8844.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8868.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/8871.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8920.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8922.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8928.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8937.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/8955.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8961.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8966.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8977.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8984.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/8995.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9005.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9017.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9023.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/904.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9062.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9069.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9070.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/909.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9091.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9099.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9102.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9106.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9111.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9126.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9144.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9149.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9156.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9158.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/916.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9168.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9180.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9195.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9209.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9212.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9217.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/922.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9224.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9247.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9250.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9251.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9265.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9267.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9292.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9293.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/93.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9313.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9333.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9345.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9351.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9355.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9360.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9394.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9397.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9399.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/940.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9431.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/9434.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9439.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9447.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9449.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9458.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9469.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9484.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/949.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9499.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/95.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9504.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9508.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9516.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9518.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/954.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9556.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9558.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9561.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9582.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9595.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9597.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9605.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9606.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9620.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9631.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9640.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9647.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9661.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9665.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9667.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9670.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9679.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9687.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/9712.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9725.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/9728.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9740.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9748.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9760.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9761.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9775.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9776.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9795.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9808.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9818.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9819.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/983.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9830.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9832.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9837.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9849.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9877.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9880.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9894.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9896.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9906.png  \n",
            "  inflating: /content/data/DATASET/Training Samples/8/9917.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9926.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9935.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9936.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9954.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9967.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9978.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9985.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9995.png  \n",
            " extracting: /content/data/DATASET/Training Samples/8/9996.png  \n",
            "   creating: /content/data/model_weights/\n",
            "  inflating: /content/data/model_weights/README.txt~  \n",
            "  inflating: /content/data/model_weights/weights_arch1.hdf5  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/drive/MyDrive/My Datasets/xPLNet.zip\" -d /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLWP5UCo0zd_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from shutil import rmtree\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, models\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n",
        "from keras.layers import (\n",
        "  Dense,\n",
        "  Conv2D,\n",
        "  GlobalMaxPooling2D,\n",
        "  GlobalAveragePooling2D,\n",
        "  MaxPooling2D,\n",
        "  BatchNormalization,\n",
        "  Dropout,\n",
        "  Flatten,\n",
        "  MaxPool2D,\n",
        "  SeparableConv2D\n",
        ")\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9p449vq7_M_"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNG-DG8G5LGZ",
        "outputId": "12a9a8a7-99a6-49ea-8f97-3c34ad67b24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 47351 images belonging to 9 classes.\n",
            "Found 11833 images belonging to 9 classes.\n",
            "Found 6576 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = (75, 75)\n",
        "BATCH_SIZE = 32\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the paths to the directories containing the data for each set\n",
        "train_dir = '/content/data/DATASET/Training Samples'\n",
        "test_dir = '/content/data/DATASET/Test Samples'\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,                      \n",
        "    featurewise_center=True,                                     \n",
        "    rotation_range=90,                      \n",
        "    width_shift_range=0.1,                  \n",
        "    height_shift_range=0.1,                 \n",
        "    vertical_flip=True,                    \n",
        "    horizontal_flip=True,                \n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_gen = data_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        ")\n",
        "\n",
        "validation_gen = data_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_gen = test_generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def create_dataset(data, BATCH_SIZE, num_images):\n",
        "    data.reset()\n",
        "    X, y = data.next()\n",
        "    for i in tqdm.tqdm(range(int(num_images/BATCH_SIZE))):\n",
        "        img, label = data.next()\n",
        "        X = np.append(X, img, axis=0)\n",
        "        y = np.append(y, label, axis=0)\n",
        "        if i == int(num_images/BATCH_SIZE)-1:\n",
        "            break\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "num_train = 3000\n",
        "num_test = 500\n",
        "num_val = 900\n",
        "\n",
        "X_train, y_train = create_dataset(train_gen, BATCH_SIZE, num_train)\n",
        "X_val, y_val = create_dataset(validation_gen, BATCH_SIZE, num_val)\n",
        "X_test, y_test = create_dataset(test_gen, BATCH_SIZE, num_test)\n",
        "\n",
        "print(f\"\\nX-train shape: {X_train.shape}\")\n",
        "print(f\"y-train shape: {y_train.shape}\")\n",
        "print(f\"X-val shape: {X_val.shape}\")\n",
        "print(f\"y-val shape: {y_val.shape}\")\n",
        "print(f\"X-test shape: {X_test.shape}\")\n",
        "print(f\"y-test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JFxAu0-Znl-",
        "outputId": "68de91e4-0211-4fba-81a6-6a88a3d185f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            " 99%|█████████▉| 186/187 [16:39<00:05,  5.37s/it]\n",
            " 98%|█████████▊| 55/56 [04:49<00:05,  5.26s/it]\n",
            " 97%|█████████▋| 30/31 [02:40<00:05,  5.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X-train shape: (3008, 75, 75, 3)\n",
            "y-train shape: (3008, 9)\n",
            "X-val shape: (912, 75, 75, 3)\n",
            "y-val shape: (912, 9)\n",
            "X-test shape: (512, 75, 75, 3)\n",
            "y-test shape: (512, 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U4pahiy8KdF"
      },
      "source": [
        "# **Creating CNN from scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using Grid Search to find best parameters for CNN+SOFTMAX**"
      ],
      "metadata": {
        "id": "JoOC516b6VgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# Define the CNN model architecture\n",
        "def create_model(num_filters, kernel_size, pool_size, num_dense_layers, num_dense_units, learning_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=num_filters, kernel_size=(kernel_size), padding=\"Same\", activation=\"relu\", input_shape=X_train.shape[1:]))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    for i in range(num_dense_layers):\n",
        "        model.add(Dense(num_dense_units, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(lr=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Define the hyperparameters and their values to be tuned\n",
        "param_grid = {\n",
        "    'num_filters': [8, 16, 32],\n",
        "    'kernel_size': [(3, 3), (5, 5)],\n",
        "    'pool_size': [(2, 2), (3, 3)],\n",
        "    'num_dense_layers': [1, 2],\n",
        "    'num_dense_units': [32, 64],\n",
        "    'learning_rate': [0.001, 0.01]\n",
        "}\n",
        "\n",
        "\n",
        "# Create a KerasClassifier object for the model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert target labels to one-hot encoded format\n",
        "y_train_categorical = to_categorical(y_train, num_classes=10)\n",
        "y_train = np.argmax(y_train_categorical, axis=1) # Convert back to original form\n",
        "\n",
        "# Use GridSearchCV to search the hyperparameters\n",
        "grid_search = GridSearchCV(model, param_grid=param_grid, cv=3, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and the corresponding accuracy\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best accuracy: \", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "Hx1rUqrkZa8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41cd9204-3e0c-4451-ad32-e7cbbd14feb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-d3ed261c6c22>:34: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=1)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 8.9489 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 80.5132 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 361.6293 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1042.7415 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2509.7683 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 5038.7129 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7943.9712 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 12551.0439 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18328.7363 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 26901.5430 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 35719.3008 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 49519.6836 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 63042.4961 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 76863.3828 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 97222.0859 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 121496.3125 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 145618.3594 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 175390.9688 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 200242.7344 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 230195.7344 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 211864.4062 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 8.1866 - accuracy: 0.8858\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 104.1833 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 527.4216 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1429.1233 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 3291.5288 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6153.0474 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 10271.0918 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 15222.8643 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 22079.4688 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 32878.4258 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 43497.8750 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 55242.1562 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 71843.7734 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 91595.5781 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 110225.1328 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 130849.1172 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 155318.5156 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 187265.5312 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 217507.7031 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 253545.6875 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 350725.9688 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 7.1206 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 83.0104 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 389.6767 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1261.1870 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2955.7021 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5580.1382 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8744.2158 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 14136.3838 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 22059.1230 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 31713.9590 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 42081.1484 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 55408.9453 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 71841.4922 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 90037.5078 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 110866.2031 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 132792.2188 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 156562.1562 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 190001.7812 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 216830.5781 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 252719.3906 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 243221.0156 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 5ms/step - loss: 4.1427 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 44.6165 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 235.8097 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 658.3443 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1634.7968 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2907.8386 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 4807.2500 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 8130.5132 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11088.5566 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 15603.8486 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 21358.6855 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 27667.4375 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 35886.8555 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 46177.7891 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 56221.7188 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 66697.0156 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 79490.7344 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 94022.2734 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 112653.5859 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 130405.0312 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 119111.6562 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 4.5254 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 48.2296 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 231.1411 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 569.5037 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1395.1766 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2613.9131 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 4587.0796 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 6857.6650 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 9992.5703 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 13900.2725 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 18521.4668 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 24646.4551 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 31405.5371 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 40454.8047 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 50796.2461 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 60959.2188 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 75101.9297 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 89560.2891 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 105013.2812 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 121818.1797 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 169490.8750 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 1s 5ms/step - loss: 3.7215 - accuracy: 0.8774\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 40.1241 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 213.0241 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 630.9932 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1255.5573 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2480.7913 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3894.0171 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6231.2256 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9258.4404 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13340.6162 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17011.5020 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 22418.3477 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 28887.3105 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 35778.2227 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 43445.6562 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 52875.1250 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 62825.5430 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 74870.7266 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 86462.3906 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 99110.3047 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 94912.9141 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 14.0582 - accuracy: 0.8768\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 165.9922 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 876.2087 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2421.8750 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5749.9429 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 10623.0986 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17972.7578 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 29527.6973 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 45357.5430 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 62992.0586 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 87148.6328 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 112048.0703 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 142690.5312 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 181839.2344 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 227134.1094 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 267761.5938 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 324426.5312 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 390782.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 444959.6875 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 529980.5625 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 478520.6875 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 12.4111 - accuracy: 0.8898\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 189.0282 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 985.6606 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3783.1060 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 7711.6802 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 14439.8467 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 23277.2305 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 37861.1367 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 51895.4570 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 75899.6328 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 100548.2109 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 133351.6094 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 178441.0625 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 219567.0781 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 266124.4375 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 328289.1250 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 400663.9062 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 459728.2812 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 538088.8750 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 627658.6250 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 874056.6250 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 9.1014 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 137.1480 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 825.8784 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2406.9180 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5995.4414 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11633.9121 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 20735.0723 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 30370.3730 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 46768.5312 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 66005.2812 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 90507.9062 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 120036.5078 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 149963.1406 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 197251.4062 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 235171.8438 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 286949.4062 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 340897.8750 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 418977.0625 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 492546.8438 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 586694.8125 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 550395.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 5.6840 - accuracy: 0.8733\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 66.0898 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 363.6097 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1286.4885 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3482.4460 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6319.4834 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11017.3633 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17690.1445 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 25979.5977 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 37419.5273 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 49312.1523 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 65633.3516 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 84218.0547 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 108772.5469 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 135875.0781 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 156411.2656 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 193431.7812 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 223619.2969 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 261973.3438 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 311601.6250 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 283016.6875 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 1s 5ms/step - loss: 6.8983 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 81.4940 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 383.0085 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1055.7402 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2404.9902 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 4862.1680 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8195.6143 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13221.5361 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 19185.3770 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 26869.4043 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 36002.5508 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 49184.1445 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 63136.1289 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 78608.3438 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 97096.0156 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 122272.3438 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 147503.3594 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 175376.7969 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 200853.2500 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 236124.0312 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 336015.8125 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 6.7094 - accuracy: 0.8799\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 92.6506 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 485.4458 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1598.7472 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 3339.6501 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 5964.8325 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 10578.4717 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 15866.7764 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 24041.6367 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 32389.1953 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 45904.1055 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 60350.7891 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 75944.6016 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 95515.7031 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 117763.4844 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 141958.6406 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 170339.0312 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 199525.7812 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 236699.9219 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 274337.7812 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 261995.2969 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 18.0249 - accuracy: 0.8768\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 305.8619 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2035.3455 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5218.5513 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13721.2148 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 27086.5352 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 44373.7109 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 71232.8984 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 97297.6875 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 150087.2344 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 198351.9219 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 251730.7188 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 316049.2500 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 388797.3438 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 507905.8438 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 597140.9375 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 708577.8750 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 822440.9375 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 971146.3750 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1111374.3750 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1018454.1250 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 18.8362 - accuracy: 0.8918\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 272.4343 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1366.2087 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4788.8110 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12002.1006 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 23288.7461 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 40260.5469 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 62875.7773 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 101832.4688 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 138750.1719 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 189333.2812 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 245903.4062 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 308926.8125 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 399769.7500 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 497839.5625 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 597782.0625 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 731099.1250 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 847845.6875 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 995416.2500 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1176864.8750 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1622434.6250 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 15.9033 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 283.2131 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1449.6562 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4404.0166 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 9625.1611 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 20067.5059 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 30852.6250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 53751.3477 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 79972.9922 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 112765.6016 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 151562.8750 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 202012.0938 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 264948.9375 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 338689.5625 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 414326.4375 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 506554.8438 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 608608.6875 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 728289.1875 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 853492.7500 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 999175.0625 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 945037.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 9.1657 - accuracy: 0.8698\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 133.6445 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 762.3932 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2134.3062 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5647.4102 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 10981.2275 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 18939.2480 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 28499.4395 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 43015.1680 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 62092.3008 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 83110.9219 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 110068.7656 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 138692.9375 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 179481.6406 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 216481.1562 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 270578.1250 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 327479.9062 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 389253.0312 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 455603.0625 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 530496.2500 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 485112.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 11.9519 - accuracy: 0.8883\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 152.4520 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 920.5747 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2498.9685 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6211.6460 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11331.6855 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 18424.0371 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 30187.0957 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 44385.2695 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 60603.7422 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 84880.6641 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 108070.6641 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 132962.2344 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 174636.4688 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 206296.3125 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 253240.4688 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 299838.1250 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 359321.6250 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 420951.7188 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 480110.9375 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 672334.3750 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 12.8089 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 161.7202 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 930.1886 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2801.2456 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6450.9634 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11906.8037 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 21217.2207 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 32852.3906 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 49293.2500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 67860.3125 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 91132.8750 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 115942.9297 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 140524.6562 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 183998.1562 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 228278.7344 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 263205.2812 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 322216.5000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 379157.9062 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 444373.5625 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 512516.3438 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 480055.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 11.8886 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 179.4271 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 982.1902 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2688.7720 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6968.8013 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 12512.5059 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21604.1914 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 35843.3945 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 54669.4531 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 75724.2734 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 106860.0078 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 136295.3906 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 178323.3750 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 226355.3594 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 274723.9375 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 337936.7812 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 410230.1875 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 470210.8125 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 547699.6250 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 637104.3125 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 585580.1250 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 13.0497 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 216.0497 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 972.2482 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3211.6006 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7745.5259 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14581.1953 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 26845.5762 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 42677.4375 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 62832.3555 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 88777.3750 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 120818.9766 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 159151.7188 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 196750.5938 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 248404.8906 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 315798.5312 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 374590.7500 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 439577.4688 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 543121.9375 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 642352.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 729003.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1020446.1250 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 11.7294 - accuracy: 0.8734\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 173.0059 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1024.0404 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3642.1997 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7888.5186 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14910.7676 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 26644.9668 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 44359.3750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 62083.9492 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 84681.4375 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 120179.5078 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 154257.7969 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 205667.3281 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 251315.1562 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 300047.5625 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 357496.4062 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 426990.7500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 504639.0312 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 600765.8750 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 678017.3125 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 649945.5000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 6.8089 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 73.5941 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 325.6100 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 853.0361 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1966.0763 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3659.7983 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7439.4727 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11409.5537 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17569.8477 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 24941.9297 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 33915.2969 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 46752.7969 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 59909.7383 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 73903.6172 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 89729.2422 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 110422.6719 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 129641.2266 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 156131.1406 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 176658.7969 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 207425.6875 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 191095.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 10.0780 - accuracy: 0.8758\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 109.9728 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 512.0056 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1507.9996 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3707.7366 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7114.7754 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11727.8760 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 19163.5781 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 27455.2695 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 39200.2656 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 51184.9961 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 68137.9141 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 87367.1641 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 109058.3203 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 128961.6953 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 162244.4219 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 188199.5312 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 224702.7812 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 262232.1875 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 309566.5938 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 426472.0938 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 7.6896 - accuracy: 0.8769\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 76.9012 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 403.4870 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1241.7306 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2852.0083 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6305.0728 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10405.2852 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 16317.7617 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 24568.7832 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 34210.0078 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 45994.1602 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 59331.9844 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 74769.9766 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 95651.9531 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 116015.6328 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 139111.0781 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 169167.6406 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 196860.7344 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 228106.2031 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 267687.6250 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 253979.2344 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 17.2613 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 312.1039 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1712.1344 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5748.7749 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14327.3906 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 26626.9961 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 47016.9297 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 69664.4531 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 105478.9688 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 153370.8750 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 217684.7344 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 279635.6250 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 358548.8750 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 443582.3750 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 547921.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 684053.3125 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 802015.9375 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 966627.6250 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1128134.8750 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1339623.1250 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1209959.1250 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 21.0908 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 369.7531 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2139.6743 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7009.1543 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13884.7109 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 29571.3867 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 49935.0898 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 81603.6250 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 117666.1406 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 166120.0312 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 241328.2188 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 305657.2812 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 381504.9062 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 493185.6875 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 614149.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 749042.1875 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 900443.6250 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1077031.5000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1260417.8750 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1449978.8750 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2041451.3750 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 14.7120 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 236.3988 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1662.1594 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5277.8872 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12677.9795 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 25069.7402 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 43367.9844 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 66432.4297 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 98879.9922 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 144893.9844 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 199548.2500 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 261011.5000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 325522.9688 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 409252.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 517959.5938 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 605845.0625 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 733249.4375 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 847449.6875 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1014733.7500 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1169023.5000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1121081.7500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 7.8287 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 162.5306 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 854.5039 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3036.3616 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6477.3193 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12886.8672 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23150.9004 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 38364.8867 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 55519.5781 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 79331.2109 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 107317.0156 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 137921.7344 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 171971.5938 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 212208.5781 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 271695.1875 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 328080.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 395300.8438 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 465592.3438 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 550317.5000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 619902.3125 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 567152.5625 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 8.3857 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 147.0136 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 935.8385 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2885.0405 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7160.7212 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 13006.2725 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 21555.3887 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 35414.6172 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 55902.0547 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 76108.6641 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 104181.2891 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 134176.2969 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 176282.2500 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 217540.0156 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 273579.6250 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 332971.4688 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 408197.4688 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 481190.4062 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 560899.3750 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 647618.8125 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 903420.0625 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 10.5967 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 186.2900 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1045.3689 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2679.0393 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6567.3652 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12614.5215 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 20734.5254 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 34012.3594 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 45433.5391 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 65920.4922 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 88444.8047 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 112312.5312 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 148676.4375 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 188790.1250 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 226917.9688 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 276093.2188 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 335275.0625 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 401991.7500 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 448037.6250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 529840.6875 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 501297.5312 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 32.9393 - accuracy: 0.8848\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 490.6027 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3418.1787 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10793.6641 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 25636.9980 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 50255.0547 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 88492.2969 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 144936.2500 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 213406.0156 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 292907.4688 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 417644.3750 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 531925.8125 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 683483.7500 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 851477.4375 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1039306.2500 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1251960.2500 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1513135.5000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1720743.3750 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2045756.8750 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2398429.5000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2195784.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 42.1023 - accuracy: 0.9007\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 766.9120 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3847.8789 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11779.0986 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 26954.9844 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 50330.3320 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 88719.3047 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 138971.7812 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 204943.5625 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 282942.4375 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 380721.0312 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 493160.1250 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 627829.8125 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 785057.6250 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 964679.6875 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1186280.1250 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1386716.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1656629.3750 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1931590.5000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2217875.2500 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3133123.2500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 43.5385 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 702.4820 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3717.7595 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10920.5215 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 25275.7324 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 51574.9219 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 89039.5469 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 132789.8594 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 198405.0156 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 288327.0938 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 384757.7500 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 498524.6250 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 661020.5625 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 840686.5625 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1035078.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1230469.7500 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1474181.5000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1753132.6250 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2031233.3750 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2410750.2500 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 2269875.2500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 18.3076 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 289.7025 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1475.9143 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4841.9736 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11258.6855 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20862.1016 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 37038.4102 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 65925.0312 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 102227.1250 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 141041.3594 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 188178.6719 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 250375.5781 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 331746.5625 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 413654.7188 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 512057.9688 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 622459.3125 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 751438.3125 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 917396.8125 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1063051.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1190972.3750 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1097982.3750 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 16.0101 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 297.1330 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1682.0117 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4789.4199 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11269.6387 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 24408.9844 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 42285.9766 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 60352.5820 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 95850.4922 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 128472.2188 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 176051.9688 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 229901.6406 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 295366.1875 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 372078.2188 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 470384.3438 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 554417.2500 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 662290.4375 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 796148.8750 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 915629.9375 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1045895.8125 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1480752.1250 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 17.0142 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 278.6412 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1773.4702 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4579.5054 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12120.9883 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23900.1914 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 36532.0508 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 58561.0312 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 92103.3438 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 124858.9766 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 169337.6719 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 238856.0312 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 312648.6250 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 392789.6250 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 484463.8750 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 583890.4375 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 705095.0625 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 844320.1875 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 983366.6875 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1147468.6250 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1104370.8750 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 14.6396 - accuracy: 0.8763\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 323.9983 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2566.3340 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13103.2061 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 39648.6562 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 104395.7422 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 218884.8750 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 427116.6875 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 762768.8125 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1192414.8750 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1772811.3750 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2814063.7500 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3711456.7500 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5199502.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6932662.5000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 9015016.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11398152.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14444237.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17710458.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 22236114.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 20480948.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 18.0350 - accuracy: 0.8893\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 362.3228 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3303.2820 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14800.3867 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 38334.2031 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 89890.6719 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 210111.0781 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 360821.7188 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 637734.5000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1010743.1875 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1528280.7500 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2248821.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3148462.5000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4155052.2500 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5503883.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7252667.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 9005376.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11377335.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14543875.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17647034.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 25131188.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 17.7431 - accuracy: 0.8759\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 414.5534 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3451.4314 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 15369.3154 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 49543.5977 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 128984.5781 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 286632.1875 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 522050.6250 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 904074.3750 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1452941.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2277659.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3238354.7500 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4673518.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6278841.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8587865.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 10720599.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13949669.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17559828.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 20985174.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 25804014.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 25107468.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 7.2244 - accuracy: 0.8768\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 149.9586 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1587.4019 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6985.6763 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 21593.0625 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 49457.8672 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 107728.8125 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 192089.6875 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 321850.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 508577.6875 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 839727.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1115017.3750 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1610807.6250 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2151324.5000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2781155.2500 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3645865.7500 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4672777.5000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6036690.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7268056.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8906040.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 8384029.5000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 7.2947 - accuracy: 0.8988\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 146.1528 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1684.5239 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8202.0166 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 27127.4023 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 69588.3906 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 134570.9062 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 264064.3125 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 448745.5625 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 712601.1875 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1044319.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1543820.5000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2188086.5000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3032973.2500 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3896077.7500 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5286015.5000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6767240.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8430626.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10677691.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12912058.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 18391358.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 5.8634 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 127.7362 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1574.9827 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6747.5059 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 21242.8633 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 52151.5508 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 108094.6797 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 205728.5469 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 344220.7812 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 560955.1250 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 831613.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1204704.1250 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1651323.1250 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2278551.5000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3004478.5000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3707334.7500 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4699659.5000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 5855250.5000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7193161.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8651912.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8452617.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 16.5634 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 562.1963 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5764.9634 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 25780.6738 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 85345.8750 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 225738.7656 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 497940.6875 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 839839.3125 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1491141.6250 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2347814.5000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3600332.5000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5062174.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6929000.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9450413.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13038754.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 16479351.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21376650.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 26621842.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 32956600.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 40409068.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 38041268.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 37.5276 - accuracy: 0.8758\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 983.5816 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8736.1572 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 40217.2617 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 118771.5000 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 272672.7812 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 545156.5000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1023913.0625 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1697497.1250 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2626149.5000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3959628.7500 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5665665.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8257782.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 10715393.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14439150.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18704894.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 22877518.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 29722022.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 36810168.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 44241792.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 63022428.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 15.9800 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 546.9999 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5731.2832 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 28056.6445 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 82535.5469 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 239951.1094 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 467599.8750 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 840719.0625 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1517450.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2299656.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3585435.7500 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5308238.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7321568.5000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 10194660.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13881820.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17850564.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23382632.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 28778412.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 35840528.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 44650156.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 43072316.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 12.5592 - accuracy: 0.8763\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 446.4240 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4107.9521 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 18189.8555 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 59971.1445 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 140553.1562 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 333342.2188 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 555305.8125 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 927198.8750 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1434192.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2189093.7500 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3095340.7500 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4386253.5000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5934756.5000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8123040.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 10221352.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13559905.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17122382.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20901940.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 25152240.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 23582458.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 10.2405 - accuracy: 0.8858\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 285.1154 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2774.6357 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12835.4629 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40468.6445 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 91891.1250 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 198739.6094 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 350799.5625 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 646596.9375 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 966811.5625 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1581446.6250 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2311299.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3247169.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4580909.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5884915.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7704883.5000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 9816237.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12054364.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 15071544.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 18984976.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 27027588.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 8.0735 - accuracy: 0.8759\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 284.4049 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2600.2900 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12575.7871 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 38083.6992 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 89180.2656 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 193831.9375 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 369863.8750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 637240.1250 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 959398.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1498424.2500 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2175049.2500 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2996380.5000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4269065.5000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5743933.5000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7517095.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 9329496.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11332715.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14031764.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 17335918.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 16866528.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 26.6641 - accuracy: 0.8643\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1048.4408 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 9826.2188 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 51703.3008 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 166216.6406 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 412996.3750 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 823364.1875 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1531410.8750 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2640460.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4140172.5000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6496642.5000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9124177.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12838451.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 18110498.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 23916760.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 30604236.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 38655012.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 49006844.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 60449500.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 72785304.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 68722280.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 18.8069 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 970.4971 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10663.1875 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 51058.6484 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 176921.5469 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 379074.5938 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 898981.4375 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1607323.1250 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2826285.7500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4427787.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6775043.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9887776.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13605092.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 19417490.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 24278248.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 32694572.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 41092836.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 52140140.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 64078668.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 80398912.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 115017944.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 36.1123 - accuracy: 0.8664\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1158.4254 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 12064.4404 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 50507.6914 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 171173.2812 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 449641.2812 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 925354.6250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1711518.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2988719.7500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4933504.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7616943.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10489414.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14912404.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20441966.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 26895226.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 35635276.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 45561080.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 57535212.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 70892864.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 88831576.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 86490496.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 16.4501 - accuracy: 0.8888\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 432.8171 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4329.4902 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 22840.1016 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 71249.5703 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 184414.7812 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 392619.6250 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 688747.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1157752.6250 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1831200.5000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2923263.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4089184.5000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6098549.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7887081.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10728402.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13783460.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 16965774.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 22059994.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 26805340.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 32899092.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 30943698.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 11.3134 - accuracy: 0.8813\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 439.2921 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3614.1602 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17727.2832 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 53661.5938 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 145739.4531 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 294532.7500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 569461.8125 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 908139.5625 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1542649.1250 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2470367.2500 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3386372.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4765262.5000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6216421.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8630362.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11110475.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13814187.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17117206.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 22179816.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 26407228.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 38118208.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 27.4926 - accuracy: 0.8893\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 832.8271 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7063.1973 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 31654.4707 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 98601.7969 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 249402.1094 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 531321.2500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 968646.3750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1555918.2500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2553733.5000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3708352.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5339973.5000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7553421.5000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10068252.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13342757.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17676138.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21478564.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 26758188.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 34198212.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 41509060.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 40870788.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 41.1281 - accuracy: 0.8738\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1589.4054 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18808.0059 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 90981.7109 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 307474.8125 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 754597.7500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1765221.5000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3276765.7500 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5644667.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8862214.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13338784.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 19035788.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26931478.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 36378452.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 48542520.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 63329872.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 79589168.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 98514264.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 119650784.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 149625152.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 140255056.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 43.0375 - accuracy: 0.8943\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1844.3108 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 16566.9082 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 75968.8906 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 250262.6406 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 693924.2500 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1471560.6250 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2729818.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4501831.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7326117.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 11260273.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 16199254.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21939900.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 31123754.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 39990220.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 52689868.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 69353984.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 85495928.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 106081800.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 129349648.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 185524192.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 29.0090 - accuracy: 0.8769\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1444.0707 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 15742.0410 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 77256.4219 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 247611.9531 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 625137.0625 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1278212.7500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2474053.2500 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 4264138.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7010506.5000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 10038219.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 15072358.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 21093756.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 28898902.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 38523944.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 47079128.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 62732584.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 80179880.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 95939488.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 117439008.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 114618936.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 17.5941 - accuracy: 0.8788\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 511.1011 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5779.9395 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 24672.1836 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 91612.3594 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 237534.9844 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 559721.1875 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 991434.9375 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1689191.3750 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2802192.7500 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4038549.2500 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5890146.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8428064.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11363549.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14841536.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 19885118.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 24706982.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 31351920.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 38403424.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 47971488.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 44609148.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 15.6797 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 627.1160 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7262.5132 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 37102.7031 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 130265.0391 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 302377.0312 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 663541.3125 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1254349.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2202059.2500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3548492.2500 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5076226.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7778391.5000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10462090.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14233485.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 19277334.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 24716452.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 31338710.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 38248740.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 48144616.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 58195348.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 82692080.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 34.6640 - accuracy: 0.8838\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1172.9042 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13339.0430 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 60771.5781 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 178515.2344 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 413510.4375 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 846728.0000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1672425.3750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2765622.2500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4571515.5000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6471788.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9580854.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13551551.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 17560714.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 23226086.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 30254818.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 38816652.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 48232392.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 58988616.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 73093000.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 72692512.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 51.1755 - accuracy: 0.8783\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2197.7380 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 23911.5195 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 112531.2891 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 345141.8438 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 873308.1250 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1840230.6250 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3641554.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6167166.5000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9909326.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14867151.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 22705826.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 30324456.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 41598100.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 55979712.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 73808864.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 91979120.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 113599232.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 144120864.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 170686704.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 162199584.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 45.6613 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3097.8171 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 31645.3066 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 157428.1719 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 523205.1875 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1392151.1250 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2682592.2500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4770165.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8449265.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 13527561.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 19808146.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 29160778.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 41294572.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 55180188.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 74328920.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 95216992.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 125877456.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 159599472.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 192718720.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 239292736.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 338297824.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 61.3548 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2717.0518 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 29254.7012 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 158174.0625 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 504745.1875 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1338953.0000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2614439.5000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5160775.5000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8045210.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 13142704.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 19766618.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 28779290.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 41128872.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 55224144.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 72038864.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 93765240.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 116045392.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 148840208.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 184665376.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 223060432.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 218452256.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 32.5923 - accuracy: 0.8768\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1418.5900 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14688.7041 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 66680.2734 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 230534.4688 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 491301.9062 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1057048.2500 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2066284.8750 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3508307.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5644352.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7931677.5000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11650618.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 17130386.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 23137726.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 31758376.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 40151548.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 49923764.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 64383744.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 78160536.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 95678592.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 90926968.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 28.5587 - accuracy: 0.9017\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1145.0764 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14385.8555 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 61328.4062 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 221101.0469 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 504620.1875 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1108535.3750 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2093188.5000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3462646.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5517440.5000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8533099.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12302732.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16958108.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 23962506.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 31443838.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40829532.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 53446128.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 66967764.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 84721088.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 101665896.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 145151616.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 33.6965 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1501.7936 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 16137.6758 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 72263.3281 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 225203.0156 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 575972.8750 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1221715.1250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2298394.5000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3833177.7500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5928880.5000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 9581111.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13066231.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18204912.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 24409184.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 33786940.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 43136356.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 54650968.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 67466120.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 82282184.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 101067504.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 99432288.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 96.5537 - accuracy: 0.8738\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4657.2090 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 52265.9023 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 283569.4688 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1044749.8125 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2318716.5000 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4624534.5000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8514638.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14905710.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 24154932.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 36664740.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 53490348.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 69326536.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 99780072.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 133943080.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 175030192.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 219945584.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 274441248.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 332709568.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 412147712.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 389528800.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 78.4633 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4291.7476 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 48946.4688 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 256099.1094 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 877814.1250 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2268781.0000 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5090768.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9375282.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16151416.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 25440038.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 38830900.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 55481100.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 79982320.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 104752376.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 140213488.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 178281536.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 226765488.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 284132576.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 348803584.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 414171648.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 604600576.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 11ms/step - loss: 101.3589 - accuracy: 0.8769\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6283.7812 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 65559.6719 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 298188.9688 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 953984.0625 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2386136.2500 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4845947.0000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9254649.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 16628594.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26013326.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 38766168.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 60583736.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 81850480.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 117505832.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 149052176.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 196232144.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 251045456.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 315907968.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 391910784.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 476921248.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 461525472.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 62.3790 - accuracy: 0.8758\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2573.3967 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 29281.1543 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 132110.9531 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 472190.3125 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1132551.1250 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2452599.0000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4302891.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7386078.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11145622.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 16408663.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 24589388.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 34467636.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 46434532.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 59143168.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 75748176.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 100450736.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 125747072.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 153266016.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 189328752.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 176399312.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 43.3072 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2317.5564 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 27001.7734 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 133153.0000 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 448298.9375 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1218955.7500 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2416642.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4331450.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7601013.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12295149.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18552548.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 26636990.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 35890196.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 49223876.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 65091412.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 84905472.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 105254048.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 129555552.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 162033104.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 198260736.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 283429728.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 38.4959 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2682.0735 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 30299.0840 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 117468.0312 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 471613.2812 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1102395.7500 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2371201.7500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4574388.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7392722.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12003453.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18581476.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 25276946.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 34193084.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 49223520.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 63737144.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 84250656.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 109169360.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 136062192.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 163051520.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 198734320.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 194373184.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 9.7986 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 129.5666 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 510.9448 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1283.3992 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3141.0378 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5883.5991 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9179.8213 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14990.0273 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 21257.4004 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 29698.4004 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 40040.3203 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 54375.9102 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 68860.2969 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 86656.6406 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 108939.1484 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 126415.2344 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 153341.2188 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 181910.5156 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 209504.5156 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 245426.8281 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 221776.7656 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 5.6629 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 75.8152 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 359.0647 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1066.4922 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2737.4666 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5563.2969 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8888.0264 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14806.0078 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 21998.8086 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 31415.3164 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 41543.1797 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 55187.5898 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 72150.9453 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 94442.8281 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 117958.3281 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 142502.2656 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 172476.9688 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 204778.1562 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 245036.8438 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 280493.3125 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 392201.5312 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 7.8522 - accuracy: 0.8789\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 97.2615 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 494.0385 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1566.4026 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3245.6948 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6511.1089 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11455.4502 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17577.1523 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 26958.6660 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 38117.5742 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 49173.6367 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 64521.6328 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 85400.1094 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 104726.2500 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 126509.3438 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 157350.6094 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 187757.7344 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 216954.8906 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 252413.3906 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 300805.8750 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 284487.7188 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 1s 5ms/step - loss: 4.2628 - accuracy: 0.8733\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 35.8284 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 228.3147 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 687.6501 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1505.8098 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2953.8738 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 4705.8203 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 7618.2559 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11609.0811 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 16133.6836 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 21354.4766 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 28182.9004 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 34547.2422 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 45227.8984 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 53619.4766 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 66365.8125 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 78880.8047 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 95344.5234 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 110752.2969 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 126724.5703 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 116605.8438 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 4.3158 - accuracy: 0.8958\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 36.0245 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 190.3278 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 513.1978 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1170.3182 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2165.2620 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3682.7798 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6118.2988 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 9428.0391 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13199.3545 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17919.9004 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 23655.1641 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 29808.5859 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 37723.6406 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 46567.8281 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 57460.1328 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 68444.0469 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 81028.1641 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 94474.5781 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 109153.2969 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 152745.6562 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 4.9692 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 51.2119 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 241.0017 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 763.3153 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1695.6903 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3216.7209 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5877.9634 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8559.8301 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12687.2627 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 17977.0723 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23562.4414 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 31036.9766 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 41166.5898 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 49710.2305 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 60898.5977 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 75934.3359 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 90148.0625 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 106365.1250 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 126515.8828 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 145118.5469 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 138111.6250 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 16.4953 - accuracy: 0.8753\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 184.1514 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1048.9198 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3264.3110 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7347.3564 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14657.0312 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 24153.9551 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 38231.9297 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 57647.6836 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 78629.7422 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 105183.2969 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 139056.8281 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 178251.1406 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 220088.8125 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 275881.8438 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 341030.0938 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 401061.9375 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 479022.3750 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 566513.5000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 652252.7500 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 593827.8750 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 11.3481 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 179.2868 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 929.2681 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2713.2100 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 6563.7290 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12487.6885 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 20968.5195 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 31151.2051 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 48161.9141 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 68075.5938 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 93239.1250 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 121437.9922 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 157346.9688 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 199776.7812 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 243021.8594 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 296240.6562 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 352159.8125 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 415106.1250 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 484384.0312 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 565126.1875 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 785860.9375 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 17.2162 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 223.1909 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 958.8483 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3144.9768 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8414.3799 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 15659.5859 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 27668.5156 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 41125.6133 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 60487.0430 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 85491.6562 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 113769.6641 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 154216.6250 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 201287.2969 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 240277.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 301135.7188 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 359514.6875 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 433304.3125 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 513483.9688 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 614053.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 689433.3125 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 657078.2500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 6.3448 - accuracy: 0.8738\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 79.4996 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 376.9953 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1174.2678 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2835.0693 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5434.3706 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 9191.3330 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 13580.3438 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20325.9961 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 29757.1953 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 40565.7852 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 51225.7930 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 66007.1562 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 81967.6406 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 106510.6094 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 121970.6250 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 144751.0625 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 175082.9219 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 203004.3281 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 237664.2188 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 218236.4219 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 7.2798 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 109.1316 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 564.6711 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1544.1288 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3974.1838 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7813.6025 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12641.6592 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 19751.3008 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 28601.0547 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 41071.7188 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 56714.5000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 69733.3281 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 94333.8984 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 114075.3281 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 148276.5781 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 176723.6562 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 215068.1562 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 247184.2969 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 294833.6562 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 343246.1875 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 473321.2812 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 5.1283 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 48.7946 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 282.7987 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 907.1098 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1902.9758 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4090.1260 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7201.1421 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 10324.9707 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 16734.6211 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 24333.9180 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 32940.0977 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 41521.6094 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 53750.6484 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 66873.2656 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 80311.4844 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 99639.0703 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 117892.2734 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 142254.3125 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 163350.8906 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 191116.2188 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 184237.5781 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 16.7979 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 312.9326 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1908.4606 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4758.7236 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11356.3691 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20958.2324 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 33865.0078 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 53234.8750 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 77769.4531 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 110163.6406 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 154502.5625 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 203919.4062 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 252990.4219 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 323986.3125 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 394625.5938 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 472042.0938 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 572633.2500 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 682208.5625 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 772090.0625 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 922127.5625 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 835040.5000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 17.5328 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 281.6631 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1553.6090 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4774.8623 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11554.9707 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 22343.9766 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 39616.3359 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 62447.1172 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 94720.9375 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 134613.4531 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 187110.9375 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 241073.6406 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 308787.1250 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 381065.8750 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 468898.1250 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 570730.8125 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 705750.8125 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 810877.4375 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 953159.6250 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1090846.7500 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1535143.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 16.6811 - accuracy: 0.8799\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 309.0045 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1682.3934 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5310.0024 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11872.3604 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 22496.2891 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 41705.7227 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 69865.3750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 100691.1094 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 149730.0312 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 202038.9844 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 259662.4531 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 336030.1562 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 431705.8438 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 519150.8125 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 632777.8125 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 742542.6875 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 881454.6875 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1022341.1250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1181673.6250 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1132698.8750 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 12.5607 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 172.8796 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 980.9080 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2858.9866 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6246.8770 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12275.1025 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20756.3535 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 29315.8262 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 42306.8047 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 62379.3125 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 82652.6328 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 111493.9219 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 140044.3438 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 173934.3750 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 211963.5156 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 263078.1562 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 309763.0938 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 371036.0312 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 433365.2812 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 504507.8125 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 461602.4688 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 5.5225 - accuracy: 0.8923\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 122.2404 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 679.1365 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2349.4417 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5277.6948 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10045.3135 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 18062.3262 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 28921.1836 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 42646.2461 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 61234.8086 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 83003.8594 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 113570.7344 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 149541.6719 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 183108.5938 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 227705.3438 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 271774.0625 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 334988.9375 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 394122.1562 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 468432.9375 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 542564.3750 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 754305.3750 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 11.2187 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 159.5831 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 805.9504 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2557.4475 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6079.2446 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11250.5420 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 20261.1855 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 30670.7910 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 45072.0625 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 64318.3125 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 88081.8750 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 119544.5156 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 154268.8125 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 191021.2500 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 233651.6719 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 291068.4062 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 333042.4375 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 410232.1562 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 484198.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 551867.2500 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 529848.8125 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 13.6637 - accuracy: 0.8758\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 181.4119 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 893.5732 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3302.8962 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7454.8589 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 15087.1211 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 25448.7168 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 45140.4648 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 61015.4805 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 91263.3516 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 121979.3984 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 161004.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 202392.3281 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 260303.2344 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 324151.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 393777.3125 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 467078.6562 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 546021.1250 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 650881.3750 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 750223.7500 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 681672.3750 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 17.2182 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 245.5029 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1208.4479 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3679.3411 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7930.3984 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14702.1230 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 25043.2617 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 40537.3594 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 54739.1992 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 78377.7891 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 103009.0938 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 129777.0547 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 169478.7500 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 212257.6719 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 262580.1250 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 319760.9062 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 368333.9688 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 428815.8750 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 505192.6250 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 586749.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 820159.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 15.3769 - accuracy: 0.8734\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 200.7090 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 819.0027 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2717.1819 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6718.9395 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13476.3408 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23876.5762 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 35200.5078 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 51681.4609 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 74395.8516 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 102164.7969 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 129618.2812 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 171612.5625 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 214410.1719 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 262875.1250 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 328578.2188 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 381069.9062 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 459206.3125 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 538709.5000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 607828.1875 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 586540.5625 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 6.0281 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 79.4791 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 450.6034 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1664.5944 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3550.0896 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6636.0762 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11444.2412 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 17665.1777 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 28078.9355 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 38711.4922 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 50054.7500 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 67124.9453 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 87199.2031 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 107590.2109 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 131821.2500 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 157294.5469 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 189567.4531 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 226360.7500 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 260303.4531 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 309644.2812 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 277112.6250 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 11.1657 - accuracy: 0.9017\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 145.2573 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 676.5113 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2027.7870 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4465.2744 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8369.7754 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13630.8916 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 19805.4473 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 27869.4180 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 39866.5586 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 55450.2930 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 75268.8906 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 94164.8281 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 115264.4219 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 143987.4531 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 174023.7188 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 207546.3281 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 244929.9844 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 285725.7500 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 328759.1562 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 455125.9375 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 6.9420 - accuracy: 0.8759\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 119.7560 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 696.9361 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2136.5334 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 4714.2871 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 8887.2881 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 14993.9570 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 20922.1953 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 33669.6641 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 47702.3281 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 63252.6250 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 81873.0547 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 105108.2734 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 127715.4141 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 166737.2344 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 193651.8438 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 231152.0625 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 274886.5000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 318062.1250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 370185.2812 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 355636.0625 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 22.3596 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 378.8820 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2229.3020 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7515.8774 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 16835.3320 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 29383.7852 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 50583.2852 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 81674.3047 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 120577.0391 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 165215.4062 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 220297.8281 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 282321.5625 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 360105.1562 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 452466.8750 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 549826.8750 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 661466.6250 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 805543.3750 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 920774.6875 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1080452.2500 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1269318.5000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1135928.1250 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 20.5049 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 301.3371 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1621.5651 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4514.7134 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 11922.2959 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23826.8164 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 40489.2539 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 66375.4141 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 96914.2969 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 135942.2031 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 183280.0312 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 241886.4062 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 313418.6875 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 390917.5625 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 485724.9062 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 597510.3750 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 693616.9375 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 816994.3125 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 987660.8125 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1130206.1250 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1567258.1250 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 28.9757 - accuracy: 0.8759\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 336.6313 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1797.7074 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5295.0625 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13504.4688 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23244.5664 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 42589.2070 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 69114.9688 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 98481.3047 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 145475.5312 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 207288.9219 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 260572.4688 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 363942.0938 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 425498.0312 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 527328.0625 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 641355.9375 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 778743.6250 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 894378.6250 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1054563.1250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1253144.7500 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1176932.1250 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 10.2209 - accuracy: 0.8888\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 158.0134 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 785.8469 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2481.9309 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 5576.5723 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10413.9463 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 19292.6094 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 29723.0898 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 41438.0938 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 63034.5820 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 83618.4766 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 108236.3516 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 139753.4219 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 179928.4531 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 223150.7656 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 268653.4375 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 327246.3125 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 378564.7188 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 445150.6250 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 521897.5625 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 476243.8125 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 7.2080 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 138.4464 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 797.7852 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2386.2019 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5543.9341 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 11214.2295 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18361.3477 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 29696.0410 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 44106.6523 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 62749.7031 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 85639.6094 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 117898.1797 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 149068.1562 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 192916.7969 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 232986.3594 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 293483.8438 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 343564.4062 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 405302.8125 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 470169.0312 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 556875.3750 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 791489.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 6ms/step - loss: 10.7033 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 175.6487 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 891.5796 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2762.1516 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 7170.8833 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 13386.5059 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20938.0840 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 34321.3047 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 54256.5039 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 75278.1875 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 105449.3281 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 128205.1562 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 163293.1875 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 210395.0938 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 259617.8906 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 319657.9688 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 374940.6562 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 461990.1250 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 523746.7500 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 629650.2500 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 591599.4375 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 32.1444 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 768.2645 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3631.8503 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 11468.3721 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 26524.5879 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 50896.9219 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 85932.1484 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 144035.4844 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 205977.8438 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 294158.6250 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 409132.5938 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 521522.1875 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 706854.2500 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 887859.8125 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1080758.8750 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1283934.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1508794.7500 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1794272.3750 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2155505.7500 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2512688.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2266472.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 26.6093 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 524.7371 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2842.7131 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 10606.3018 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 21454.2090 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 50814.6914 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 80805.4844 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 130607.6484 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 193937.4375 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 264466.1562 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 383201.0938 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 509359.5938 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 648647.0625 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 809839.4375 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 980686.2500 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1209188.6250 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1479580.2500 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1729433.1250 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2053273.1250 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2408582.5000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3307563.5000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 29.5283 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 549.6620 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2882.7034 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 9704.4414 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 24330.2656 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 48243.1953 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 84609.5156 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 131381.6094 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 203793.7500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 305846.3125 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 405826.7812 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 539439.5625 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 667509.5000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 875884.1250 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1063017.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1302727.5000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1515178.2500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1792917.6250 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2125700.7500 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2441114.5000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2334853.5000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 15.6537 - accuracy: 0.8738\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 331.9917 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1881.0840 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5391.3242 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11898.0898 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23276.1680 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 43259.1953 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 64882.7344 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 98761.1719 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 138832.4844 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 187214.1406 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 240909.8750 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 314117.6875 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 384153.2188 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 466398.1250 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 572629.2500 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 675845.6875 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 810543.3750 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 947859.1875 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1098538.5000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1007941.2500 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 14.1351 - accuracy: 0.8883\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 267.7986 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1618.1962 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5122.4248 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13241.5195 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 26017.8262 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 45338.0391 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 72733.1250 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 101405.4062 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 153406.8125 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 206436.5469 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 271480.7500 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 348905.8438 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 433274.9062 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 556179.4375 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 665107.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 781758.8750 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 934699.6875 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1088339.8750 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1260204.2500 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1778379.1250 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 15.2720 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 323.6268 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2114.1060 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5898.5850 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14584.0840 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 25953.9980 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 42812.0117 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 69697.3125 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 106216.2969 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 138390.4844 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 195839.4219 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 264568.7812 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 337688.7812 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 410935.6875 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 529273.2500 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 628746.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 777989.2500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 888494.2500 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1024816.6250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1200100.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1157084.5000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 9.0845 - accuracy: 0.8753\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 271.1434 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2822.3516 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11926.1152 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 39342.5508 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 90640.6016 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 191015.7500 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 380303.9375 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 640725.6875 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1034147.9375 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1587924.7500 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2211191.7500 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3155394.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4347399.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5708657.5000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7324430.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9534917.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11818305.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14816858.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18362700.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 17170916.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 12.9850 - accuracy: 0.8928\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 295.4402 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2628.7485 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12142.8320 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 37816.1641 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 93221.8438 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 202806.2969 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 359638.8750 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 647782.2500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1030621.4375 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1540141.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2199637.5000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3083720.2500 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4310816.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5613379.5000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7347552.5000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9109559.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 11783140.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14486743.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 17282114.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 24814610.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 13.3481 - accuracy: 0.8774\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 352.5027 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4050.8528 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16531.2031 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 52892.0352 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 123312.2812 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 257571.2344 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 482541.3750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 807915.4375 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1251711.1250 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2025767.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2685240.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3880994.7500 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5068268.5000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6975049.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9027098.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11643009.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 14630653.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18071878.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21758626.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 21446656.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 8.9651 - accuracy: 0.8763\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 158.6501 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1434.8168 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5420.5713 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 17484.3594 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 41223.2148 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 82493.3984 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 158546.0781 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 250185.6875 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 412822.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 650658.1875 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 905090.1875 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1243056.8750 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1843113.5000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2366049.7500 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3082649.7500 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4000874.5000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4965163.5000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6085799.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7339413.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7027197.5000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 7.8712 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 166.4813 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1468.2131 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6458.8389 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23304.4844 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 47773.6641 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 114891.4141 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 216280.1094 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 349113.6250 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 572979.5625 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 876379.4375 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1288490.8750 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1740709.2500 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2404324.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3203820.2500 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4158857.2500 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5271379.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6594968.5000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 8117349.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9993776.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 14266410.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 8.6766 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 178.7781 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1782.3430 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7947.1313 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 23320.9922 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 67004.8906 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 128174.0938 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 226965.1875 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 406827.4688 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 656269.1250 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 951099.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1381561.3750 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1954281.8750 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2563574.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3515234.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4508442.5000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5678402.5000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7235079.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8680962.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10436218.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 10354485.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 8ms/step - loss: 20.9905 - accuracy: 0.8888\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 613.4913 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 5254.5615 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 27815.3301 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 83308.6484 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 219893.8125 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 448191.0938 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 854364.1875 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1476249.3750 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2255222.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3454083.5000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5017076.5000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7040660.5000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9499368.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12562716.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15898391.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 19555080.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 25229952.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 30674742.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 38082368.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 35482880.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 16.1809 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 592.0975 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5105.3120 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 23974.0176 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 78361.1406 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 200933.6250 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 416628.1562 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 817336.6250 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1370756.8750 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2151065.5000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3307643.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4867116.5000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 6559858.5000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9538621.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12150586.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 15229078.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 19315298.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 24505476.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 30276326.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 36911452.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 53194704.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 17.4066 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 622.4512 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5997.4727 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26818.5566 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 78897.7812 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 213736.5781 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 435667.2188 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 827054.3125 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1431435.1250 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2177346.5000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3460227.2500 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4812961.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 6836382.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9190635.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12753599.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16512380.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20477074.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26032806.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 32133672.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 38996128.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 38181028.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 10.4814 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 242.2173 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2381.3982 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10891.9844 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 34123.2344 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 84126.2656 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 189311.8438 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 359392.6250 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 607687.0625 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 949315.7500 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1394645.2500 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1991297.1250 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2946010.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3954816.5000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5180311.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6742210.5000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8578133.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10424669.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13176444.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 16129211.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 15039778.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 9.3057 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 284.8346 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2546.2080 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11200.0117 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 37995.5664 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 89168.3359 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 188210.6094 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 364251.2812 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 611650.5625 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 936509.3750 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1378828.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2061926.8750 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2807987.5000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3793998.2500 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4993355.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6203048.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8163832.5000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9959882.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12712689.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 15658930.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 22086022.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 9.6609 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 295.3045 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2708.7766 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14711.3535 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 47813.0547 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 115118.1875 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 265122.6250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 468668.1250 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 793817.3750 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1214593.2500 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1898591.1250 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2757780.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3910601.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 5191156.5000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6867723.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9009382.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11663402.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14572526.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17651648.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 21459462.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 21060082.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 22.0424 - accuracy: 0.8738\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 741.7524 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6987.4751 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 33993.0859 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 112256.1484 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 271557.5625 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 584671.6875 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1111967.1250 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1902512.1250 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3040399.2500 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4638601.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6571718.5000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9718060.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12648312.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 16961410.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21601742.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 27601108.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 35987836.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 44034516.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 54556016.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 50960356.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 37.3847 - accuracy: 0.8858\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1359.8221 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14396.1240 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 61684.5898 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 203447.0938 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 501275.6562 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1007348.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1954184.3750 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3241902.2500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4950227.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7968798.5000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11142317.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15401208.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 20418694.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 27654102.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 36621228.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 47594620.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 59620568.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 71582224.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 88380736.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 126672600.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 37.4355 - accuracy: 0.8759\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1265.6869 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15133.8799 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 67343.8672 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 214658.1406 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 562271.8750 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1107864.1250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1979364.8750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3434149.7500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5546518.5000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7846872.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 11085279.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16189867.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 22080964.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 28539032.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 37494216.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 48965912.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 59937364.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 73460608.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 89172512.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 87933088.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 12.0562 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 366.5563 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3325.1819 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 15907.4014 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 52157.5352 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 126303.3047 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 298556.6562 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 529260.9375 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 961368.4375 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1516446.2500 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2163574.5000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3158046.2500 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4438879.5000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6187725.5000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7890362.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10203748.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12894211.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16423628.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 20263744.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 24852514.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 23404782.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 14.2059 - accuracy: 0.8763\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 504.3727 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4493.9434 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 24510.9727 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 75657.5469 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 182222.2188 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 373072.5938 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 689135.3125 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1233544.7500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1872007.2500 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3068194.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 4425824.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6086935.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 8328291.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 11083707.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14234852.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 17765440.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 22429292.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 27865528.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 33511674.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 48165788.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 20.4357 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 562.9209 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5578.8364 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 21541.0176 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 79412.7578 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 180104.4531 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 393190.1250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 696806.3750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1266139.3750 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1950926.1250 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2923092.7500 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4141327.5000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 5960889.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7869241.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 10532955.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 13879861.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 17637198.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 22555342.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 26939048.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 33505030.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 32508358.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 46.1894 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1895.6416 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19551.8535 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 97688.6562 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 289889.2812 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 769733.5625 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1586138.0000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2808799.7500 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 4503741.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7598673.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11704650.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16750050.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 23367030.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 31402296.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 42212400.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 54232744.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 67940504.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 85699296.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 104988048.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 128725104.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 120507928.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 40.0018 - accuracy: 0.8883\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1737.8379 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15413.4912 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 65330.6484 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 191884.2344 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 510959.5938 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1030190.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1753593.5000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3169492.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4637676.5000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 7821544.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 11035751.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15598450.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 20646298.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 27426282.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 35640164.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 44829712.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 57997648.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 70785608.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 85720912.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 122209152.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 33.8253 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1837.1389 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 22148.3184 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 96229.9297 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 358910.2188 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 821599.6875 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1698506.0000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3273346.7500 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5415213.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8985145.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12971992.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 17632976.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 26341392.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 35586816.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 47825596.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 60314112.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 77130056.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 98389016.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 120269384.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 146322112.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 141816128.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 21.5769 - accuracy: 0.8628\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 929.8945 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 9135.6191 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 45052.6484 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 140166.6094 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 352420.2188 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 693957.6250 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1359601.3750 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2316100.2500 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3528649.7500 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5074922.5000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 7861919.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 10911203.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14519111.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19421134.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26976766.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 32917216.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 40955044.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 50773916.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 63228104.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 58979168.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 17.1155 - accuracy: 0.8913\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 713.6640 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 6811.7827 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 32261.6582 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 94793.9922 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 266318.2188 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 499750.4375 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 999033.3750 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1707936.6250 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2625260.2500 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3877425.7500 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5620953.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8112787.5000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 10728819.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14141325.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 18721698.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 22550104.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 29162132.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 37225112.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 44089132.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 62796972.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 18.8160 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 864.4685 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9230.0449 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 43293.1641 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 131978.1250 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 327407.8438 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 774952.0625 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1378700.7500 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2302259.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3532884.7500 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5705777.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7900409.5000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11713599.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 15651002.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20615492.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 26650120.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 34303564.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 42316836.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 50847940.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 62466936.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 60334368.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 96.1748 - accuracy: 0.8638\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3449.2722 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 33790.6523 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 162826.3281 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 502707.9688 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1329149.7500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2623068.2500 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4962779.5000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8428559.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12919761.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 19518496.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 29431078.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 40933148.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 55606364.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 73896664.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 96808400.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 120234160.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 155119744.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 192571120.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 232696688.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 216227136.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 41.7117 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2162.5212 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 22286.2344 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 124164.6641 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 499419.8438 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1105469.0000 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2547505.7500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4691996.5000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8323832.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13652765.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 20610904.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 29631354.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 41859148.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 56285592.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 73371408.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 99059064.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 119613112.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 147884960.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 187990624.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 233002256.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 329591136.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 48.6024 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2455.1384 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26287.7168 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 132632.3125 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 442122.6562 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1097327.5000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2182123.7500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4363857.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7648763.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11999653.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 18301776.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26700188.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 37871216.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 50264028.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 67770264.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 89418008.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 114189960.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 141953088.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 173693216.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 217861072.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 212325904.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 33.6785 - accuracy: 0.8738\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1179.8365 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12599.9834 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 66875.2422 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 217397.0000 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 580322.8750 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1188299.3750 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2271549.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3735213.7500 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5958598.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9590157.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 13397903.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 19009808.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26356422.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 35556276.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 42684616.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 55904888.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 69754080.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 85885368.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 106443352.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 99478208.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 30.9871 - accuracy: 0.8908\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1152.3722 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14395.6143 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 69734.3359 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 211362.5312 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 571377.3125 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1160864.7500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2016253.1250 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3377016.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5611876.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8301938.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12409241.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17382218.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 22681330.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 30558172.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 40524940.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 51786032.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 64959404.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 80802288.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 98222200.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 140240288.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 21.4757 - accuracy: 0.8769\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1045.7183 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15013.8193 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 73509.3203 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 251146.2969 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 636797.0625 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1323908.2500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2521306.2500 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 4411291.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6834455.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10307610.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15504854.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 22453642.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 29925344.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 39103676.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 49755096.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 66054184.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 80652008.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 102432816.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 122565256.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 120527576.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 12ms/step - loss: 90.6812 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5483.5732 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 57107.9609 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 314336.5000 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1084850.3750 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2477018.7500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5447713.0000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9893838.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 16916260.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 27717434.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 42442476.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 60240868.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 84525536.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 111850344.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 151965536.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 193632048.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 240471072.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 307429152.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 373798080.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 453228640.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 428065792.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 139.0795 - accuracy: 0.8918\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6780.0054 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 77644.3516 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 360686.5312 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1172659.6250 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2813815.2500 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5607735.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 10122562.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 17044672.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 27089774.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40094700.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 58466716.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 79743848.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 109785872.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 147059328.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 184497840.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 233816144.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 290948640.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 354560672.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 444646336.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 629512384.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 89.5967 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5125.3330 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 56526.5000 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 280468.4688 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 937045.3750 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2221860.5000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4355005.5000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 8015149.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 13840378.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 22813228.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 34203304.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 50212504.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 70475160.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 95668888.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 126429696.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 162808992.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 219737712.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 260432768.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 319811296.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 390174720.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 387496000.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 52.2165 - accuracy: 0.8818\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2047.3782 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 25684.6465 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 123268.5469 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 400797.4062 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1064050.6250 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2493912.0000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 4567020.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7175530.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11492600.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 17300610.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26298968.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 37191932.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 48989628.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 65376772.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 85027000.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 109611168.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 133846600.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 165480800.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 204482016.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 192720784.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 50.1689 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2513.9712 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 28308.4512 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 140901.8438 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 419503.6875 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1060381.1250 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2259508.2500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3819195.2500 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7258812.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10756967.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17641798.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 23064216.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 32436174.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 44967648.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 60190360.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 79140576.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 98955776.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 123834328.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 153574896.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 190649632.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 271605472.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 63.8479 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3137.1733 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 31082.1953 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 170803.0000 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 518596.8750 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1282091.5000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2685651.2500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4937688.5000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8437064.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13361146.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 20337140.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 29344606.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 42942024.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 57186676.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 74529544.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 96027416.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 119577992.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 150899264.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 183306704.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 228924240.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 222238416.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 10.8787 - accuracy: 0.8888\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 155.6625 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 850.3366 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2803.5217 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6063.6753 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11584.3867 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 20788.5820 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 33677.2070 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 46012.6211 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 66643.6562 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 86489.2188 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 115893.1328 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 151867.9531 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 189612.7656 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 229141.6250 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 283221.4375 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 336396.9375 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 395500.8125 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 464470.1562 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 518692.1250 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 476212.1875 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 14.6278 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 173.4140 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1019.7715 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2909.7058 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5889.7710 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12832.1680 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 22133.9746 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 33694.8086 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 48524.5820 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 67451.2422 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 89656.1250 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 120269.7422 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 148977.1094 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 188355.8125 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 228417.7656 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 279311.1250 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 337895.5000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 394043.2500 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 459913.1562 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 540715.4375 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 762478.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 26.6293 - accuracy: 0.8829\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 348.8104 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1441.1277 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3785.2507 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9230.4277 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 18012.2754 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 29102.6406 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 43191.6094 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 63546.2344 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 88122.6328 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 121303.6719 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 159822.7656 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 203403.7031 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 251938.5469 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 307802.0938 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 368791.1875 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 451140.7500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 529578.9375 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 618283.6250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 702650.6875 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 672866.6250 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 9.3324 - accuracy: 0.8683\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 127.5249 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 589.6603 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1721.3397 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3922.4651 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6779.8335 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11492.1943 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 17837.3965 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 25139.4004 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 35480.1055 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 47573.9023 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 60923.4805 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 78898.1875 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 97112.2109 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 119116.0625 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 137543.9219 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 168165.8281 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 197077.0938 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 233731.5625 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 269027.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 245563.9375 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 9.8421 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 113.5806 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 597.5789 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1706.7302 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3811.9023 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7400.6934 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 12128.2578 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 18313.7578 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 29466.3184 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 38508.4102 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 51695.7852 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 68372.8203 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 89060.4219 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 112705.8984 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 141020.9062 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 168356.7812 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 200176.0938 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 234052.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 280958.2188 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 321256.6562 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 456763.9375 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 9.0763 - accuracy: 0.8784\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 99.8787 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 474.3412 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1550.2865 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3468.2588 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7115.3281 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11446.6768 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19148.1562 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 29497.5547 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 40866.3359 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 53253.2656 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 71398.7734 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 92214.7891 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 117009.5234 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 143730.5938 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 169368.6875 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 203345.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 237068.4375 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 277032.3125 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 320756.2812 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 307394.5312 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 13.0413 - accuracy: 0.8753\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 212.0787 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1405.9473 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4240.7192 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10739.0059 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 19165.7734 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 34119.4062 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 56991.8477 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 90418.7734 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 120848.5234 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 164522.0938 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 219558.2188 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 278735.7188 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 341323.3750 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 428145.9375 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 527158.2500 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 641964.8750 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 758033.8750 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 901385.3125 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1021437.9375 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 943296.0625 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 23.6681 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 317.6263 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1553.0781 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4009.0103 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9567.5596 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18389.8770 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 34083.2656 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 53311.6875 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 84516.3203 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 122439.8125 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 161918.5156 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 227994.3438 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 299492.3750 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 370636.9688 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 463669.8750 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 579560.1250 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 677419.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 812348.2500 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 954912.0625 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1095921.2500 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1561674.5000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 24.3842 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 318.3924 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1471.4607 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4973.0449 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10350.8350 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21897.7715 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 35561.9062 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 60907.8828 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 91424.7500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 132759.0625 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 181153.1250 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 227956.6250 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 303707.8750 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 394896.1250 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 498823.5938 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 597885.5625 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 723349.2500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 855861.3750 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 963758.6250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1170902.1250 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1095403.5000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 10.7652 - accuracy: 0.8718\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 137.5949 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 700.6492 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2125.3557 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4816.3315 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8934.4570 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14554.6719 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23027.7363 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 33062.6445 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 48544.6836 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 65349.8828 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 86942.7812 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 115506.9922 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 139313.5000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 173769.2500 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 207378.8594 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 245843.1094 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 288946.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 343844.5625 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 381212.1875 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 350720.0312 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 13.2776 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 222.2126 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 947.3200 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3361.3989 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6722.9692 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13344.8027 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 21963.7871 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 34211.8750 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 53258.1797 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 72727.6875 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 97085.6328 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 126056.7344 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 165882.7188 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 208477.6562 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 256807.7812 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 308616.4688 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 358925.0625 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 455297.3750 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 519473.7188 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 612283.1250 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 870875.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 9.1954 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 165.1685 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 872.6595 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2389.5249 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5565.5938 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 10891.8096 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21603.4375 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 33444.9727 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 49089.8320 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 72953.4062 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 98363.4375 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 129345.4219 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 171377.6250 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 211604.8125 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 269021.4688 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 325514.0938 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 385114.2812 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 468367.3125 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 560558.5625 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 632711.3750 - accuracy: 0.8893\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 605423.7500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 61.7109 - accuracy: 0.8768\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 796.1173 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4637.1201 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 12645.0615 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 28234.2891 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 54284.3750 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 87911.4062 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 134778.8906 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 204923.5469 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 278595.8750 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 388072.3125 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 488641.0938 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 627806.8750 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 799769.9375 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 981712.8750 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1170677.8750 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1363761.5000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1622768.3750 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1893495.7500 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2264565.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2047199.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 41.9429 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 599.8028 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3303.8582 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 9368.1348 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 19238.3848 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 43751.0898 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 68681.3359 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 115644.6406 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 169381.2188 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 242041.4219 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 325103.1250 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 410666.5000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 540637.6250 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 665471.8125 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 842360.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 997490.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1209898.8750 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1417331.3750 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1676302.1250 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1924230.1250 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2716944.7500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 11ms/step - loss: 42.4581 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 693.1328 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3228.2075 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10757.1055 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 23017.2910 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 46106.0703 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 74919.5156 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 125460.9297 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 194845.1250 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 270697.5000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 366219.8438 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 477862.1875 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 628881.0625 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 748380.1250 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 940814.1875 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1164658.1250 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1379769.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1588738.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1922465.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2244262.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2086151.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 22.7297 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 352.2607 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1558.3142 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5501.6978 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 12069.0684 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 22990.6152 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36234.8359 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 60224.9570 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 89292.4531 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 119833.7344 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 162479.5469 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 224945.7188 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 286400.0312 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 369967.0312 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 455539.7500 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 540528.3750 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 669431.9375 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 801752.3750 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 920774.9375 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1066123.7500 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 974859.8125 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 20.7723 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 292.0208 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1525.8245 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4345.2461 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11151.5264 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19276.5547 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 34638.0625 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 52841.4766 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 77604.9531 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 117610.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 151477.1250 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 198197.2500 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 253460.4844 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 319392.6875 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 385659.0938 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 480684.1250 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 569446.5625 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 678341.0625 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 798927.3125 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 942035.1875 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1314655.1250 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 16.3999 - accuracy: 0.8759\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 244.0820 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1407.9044 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4441.6694 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10277.8291 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 20565.8262 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36131.1133 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 54167.1836 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 84963.1641 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 121914.7500 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 160997.9062 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 223866.4375 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 289200.2812 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 368169.8438 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 443082.4375 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 539156.0625 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 656204.8125 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 786806.7500 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 900415.6250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1057098.3750 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1011453.0625 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 22.7362 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 337.1494 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1413.6373 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4507.7383 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 10655.1279 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 19284.1602 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36637.1406 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 59095.4883 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 92409.9141 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 129022.1250 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 180408.0625 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 232379.5625 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 305382.4062 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 392608.2812 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 481168.4062 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 588406.3125 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 709328.8125 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 815262.8125 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 959401.7500 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1122753.6250 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1023484.0625 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 30.1016 - accuracy: 0.8828\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 606.5504 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2365.1628 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7909.2764 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 16138.4492 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 29924.3965 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 55271.6758 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 77400.6797 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 114543.0469 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 153823.2812 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 215395.0781 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 274259.6875 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 348539.2500 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 452426.9375 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 555091.0625 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 644877.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 773685.7500 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 932187.0625 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1077848.2500 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1291819.5000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1806100.1250 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 40.1989 - accuracy: 0.8694\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 454.1638 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2561.9409 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6976.8774 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 15928.3594 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 30320.4551 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 50456.7734 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 83765.7031 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 114537.4062 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 156534.6094 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 219395.9844 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 296048.0625 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 376378.6875 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 464582.0312 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 582434.2500 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 706501.1250 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 845451.7500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1025226.3750 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1157722.2500 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1353134.8750 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1290684.7500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 18.7604 - accuracy: 0.8778\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 305.3498 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1327.7697 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4658.0996 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8965.1240 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 17421.1719 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 28205.4277 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 44739.4688 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 63086.5078 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 91026.0156 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 119971.5859 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 159423.5938 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 196997.2656 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 251555.0781 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 306226.7500 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 367748.2500 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 451271.2188 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 531527.6250 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 617462.5000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 727218.9375 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 654804.9375 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 13.2791 - accuracy: 0.8913\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 161.3002 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 776.6301 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2880.8408 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6737.9639 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13158.4160 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 21124.4688 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 34253.2305 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 51652.6367 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 66538.1328 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 95098.9062 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 124857.6016 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 164087.2812 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 204143.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 266080.6875 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 320693.5000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 392382.9062 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 472961.0312 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 561310.5000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 651455.4375 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 913324.4375 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 22.1896 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 294.3654 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1300.6681 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 4031.8721 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8527.3477 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 16063.9072 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 29249.1836 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 44284.2734 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 60039.9844 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 92746.1562 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 125474.8516 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 163978.3594 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 216369.5469 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 265506.7812 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 325611.1875 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 396437.5000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 472280.4375 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 547955.1875 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 669697.5625 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 756577.7500 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 714175.7500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 36.1862 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 784.3234 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4088.2957 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13218.7803 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 30178.0703 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 55505.1328 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 97784.3359 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 161659.6875 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 230373.7656 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 329993.5625 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 441180.8438 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 569367.4375 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 749563.3125 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 918677.9375 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1115634.8750 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1405761.1250 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1604020.2500 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1901778.2500 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2244171.2500 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2550539.5000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2327275.5000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 43.8171 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 835.5929 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4560.6938 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 14014.0557 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 33844.2734 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 63778.1953 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 106002.6328 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 164404.1875 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 250490.1406 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 346786.1562 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 468514.9062 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 594068.3125 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 775373.2500 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 973159.6250 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1166903.6250 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1458047.3750 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1693821.1250 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2011998.2500 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2317222.5000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2758152.7500 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 3827509.2500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 43.3511 - accuracy: 0.8833\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1011.6458 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6102.5342 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 16462.1387 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 37159.6641 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 66689.1172 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 120316.1094 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 180530.8750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 269901.4062 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 381385.4062 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 520361.4062 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 694029.8750 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 883030.0625 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1108037.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1343983.7500 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1639059.6250 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1943782.1250 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2294788.2500 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2726313.2500 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3191388.2500 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 3019201.7500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 14.2516 - accuracy: 0.8753\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 300.5524 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1723.3540 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6103.3403 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13236.8633 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 26086.9062 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 43314.1602 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 66071.7891 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 101863.9453 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 132446.6562 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 186822.1250 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 233736.6250 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 317343.9062 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 391709.8125 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 463056.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 572467.5625 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 714359.9375 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 834115.9375 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 975145.6250 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1148754.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1053536.6250 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 28.9317 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 484.3310 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2310.8455 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7281.8867 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 16382.9268 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 29646.0762 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 50429.0234 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 78724.7734 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 112256.8047 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 158120.3594 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 207229.1562 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 288491.8750 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 361297.9062 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 467435.1562 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 576140.8750 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 694033.8125 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 821800.8750 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 988878.4375 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1151481.6250 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1337875.3750 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1893378.7500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 33.5960 - accuracy: 0.8734\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 503.7043 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2937.6594 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7810.0825 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18066.0898 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 35281.0742 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 58292.8359 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 92126.1875 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 134478.0312 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 188249.1875 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 251612.5938 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 338001.0938 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 427730.9062 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 521289.3438 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 649376.1250 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 806164.8750 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 952025.7500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1151543.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1319604.1250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1513664.6250 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1440221.2500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 80.4539 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1466.0288 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9709.8789 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26901.3691 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 64085.7852 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 128169.2500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 208700.8750 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 341192.6562 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 491195.0938 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 697758.5000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 944672.1875 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1219539.7500 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1579417.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1944229.5000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2468968.5000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2928316.5000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3514411.5000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4168433.5000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4856680.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5561581.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 5089212.5000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 66.3274 - accuracy: 0.8913\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1590.6879 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8720.3701 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 28040.9082 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 63577.2148 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 136737.0000 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 246456.5000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 369439.0312 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 566380.0625 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 753284.6875 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1006143.2500 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1329063.5000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1685044.8750 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2112550.7500 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2594277.7500 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3122117.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3785550.7500 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4487908.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5213659.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5962820.5000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 8403247.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 106.6101 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1682.6136 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9455.0957 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 25099.1777 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 53391.0625 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 100677.4141 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 173767.5000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 286296.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 408247.5625 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 580895.8750 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 785909.1875 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1088924.8750 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1353866.3750 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1802073.6250 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2129221.5000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2797534.2500 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3203186.7500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3960704.5000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4526601.5000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5316096.5000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 5050038.5000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 38.8057 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 828.6306 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4108.4883 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12284.7832 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 27564.8203 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 50127.1953 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 89680.7734 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 143784.5156 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 212124.7656 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 293450.8125 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 411153.4375 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 517662.3125 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 673813.3750 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 855114.4375 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1064258.3750 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1293418.2500 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1461394.8750 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1754626.6250 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2059274.2500 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2379162.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2201142.5000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 35.7463 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 583.9273 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3542.5391 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11487.7969 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26098.8965 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 52408.4844 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 85502.1094 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 135247.4062 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 211236.4844 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 287539.6250 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 392972.5625 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 523751.3125 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 659582.2500 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 850328.2500 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1030712.1250 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1268655.5000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1521998.8750 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1843895.6250 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2105311.2500 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2477183.2500 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 3469857.5000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 27.1594 - accuracy: 0.8764\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 678.9440 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3192.5513 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 10499.6895 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 23953.9707 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 46894.6875 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 88411.1641 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 138623.2344 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 194005.1406 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 271099.6875 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 395682.5312 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 502361.4688 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 637658.5000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 810050.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 987388.5000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1237633.5000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1508508.7500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1800860.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2056418.6250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2410255.2500 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2317442.2500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 4s 10ms/step - loss: 17.3979 - accuracy: 0.8838\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 582.8500 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5615.4609 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26522.3887 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 80918.2109 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 187391.2656 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 418873.9688 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 820026.5625 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1388548.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2127614.7500 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3254040.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4744932.5000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6573614.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8530826.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11499101.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14958095.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 18706218.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 23521264.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 29019262.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 34583296.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 32254970.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 29.4511 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 828.2566 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 7020.1953 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 33712.9727 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 100486.4844 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 269908.8125 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 547276.2500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 935836.3125 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1664653.2500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2592856.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3906115.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6077967.5000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8263913.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10802270.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14436200.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 18253162.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 24000092.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 29551330.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36822724.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 44022100.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 63285948.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 32.6111 - accuracy: 0.8734\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 935.3984 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8584.6729 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 42105.9531 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 121893.6406 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 294954.7188 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 560226.3750 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1046433.8750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1716855.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2843715.7500 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 4319668.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6112441.5000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8584694.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11780089.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15992642.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 20831618.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26053994.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 32067542.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40987640.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 49878528.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 49211824.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 34.7580 - accuracy: 0.8623\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 917.5491 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7684.8916 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 32101.8301 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 93847.2109 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 234822.0312 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 475030.0000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 813435.3125 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1409552.7500 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2204578.7500 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3489201.5000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4617976.5000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6682342.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8934968.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11978188.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15103063.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19309638.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 23983752.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 30154290.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36263328.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 33920056.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 15.1980 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 523.2930 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3730.5647 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 21695.0352 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 59055.0586 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 141397.6875 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 288771.9688 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 583424.0625 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 908366.6875 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1447328.7500 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2129076.2500 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3164423.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4387532.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5722937.5000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8017281.5000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9819897.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 13250591.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 15623441.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 19697588.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 24010172.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 34661208.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 16.8645 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 407.7527 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3809.2971 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 18841.9746 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 58167.8789 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 141396.4062 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 268650.6250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 552779.3750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 891475.3750 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1293028.8750 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1968417.8750 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2983652.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4021085.5000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5501391.5000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7705388.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 9602753.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12222315.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 15214105.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 19305322.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23737910.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 22758628.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 34.9271 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1179.1857 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 10302.5449 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 49119.0078 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 176468.1094 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 435980.8125 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 894973.9375 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1839506.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3023954.2500 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5132558.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7910860.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11661790.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15671751.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 22145564.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 28768220.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 37568144.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 48829972.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 60054224.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 75607648.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 90931232.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 84476472.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 28.1562 - accuracy: 0.8883\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1236.7593 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14380.2383 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 74389.1953 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 228481.4531 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 557659.6875 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1165690.7500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2183626.7500 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3762582.5000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5706259.5000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9285353.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12332486.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 17247810.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 24354724.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 32566636.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 41126804.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 53714536.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 66714420.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 81986464.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 100672000.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 145757152.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 40.5513 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1762.4648 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13807.6055 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 76720.6328 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 221278.5469 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 502145.7500 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1178931.5000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2228861.5000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3539583.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5349382.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7954282.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11194701.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 15949103.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 21000722.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 28344418.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 35845448.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 45641880.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 56795408.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 70681272.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 85084432.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 84239912.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 28.1307 - accuracy: 0.8763\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 913.7440 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9310.6689 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 38562.3945 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 138140.4531 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 305227.5938 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 624302.3125 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1188817.2500 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1996486.8750 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3246624.7500 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 4771918.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6760361.5000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9346801.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 12875241.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 17849080.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23594324.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 29241616.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 35689024.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 45498072.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 54758208.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 52238356.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 7ms/step - loss: 24.7507 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 815.0261 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6220.2046 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 28665.5137 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 80400.0703 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 191388.0938 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 399132.0625 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 762474.7500 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1294645.7500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2008748.6250 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3003221.2500 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4234403.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6064627.5000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 8281121.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 10849590.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14176523.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 18381646.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 22568122.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 27980354.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 34362464.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 49206340.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 24.0990 - accuracy: 0.8679\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 839.9780 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 7590.8389 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 37993.0430 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 116113.1016 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 280285.5000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 621137.8125 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1133952.3750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1921100.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3177163.2500 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 4868553.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 7083828.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9824327.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13674353.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17621148.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 23529284.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 29661940.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 36719768.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 45832996.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 55274884.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 53354528.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 60.4505 - accuracy: 0.8773\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2370.2864 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 20784.0352 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 99081.7344 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 297351.8438 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 780960.5625 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1524832.2500 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2753655.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4883398.5000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8228516.5000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12587801.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 17720950.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 25990476.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 34024240.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 44703028.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 58470560.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 77188288.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 94839536.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 116308480.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 142470112.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 133329552.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 96.9698 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3029.1592 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 38567.0430 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 184341.7188 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 535811.4375 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1312077.8750 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2795284.5000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4971153.5000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8265938.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 13625950.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 20198820.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 29504892.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 41916676.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 59169408.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 76474840.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 95244528.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 122748496.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 154689904.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 189296656.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 234058288.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 334993664.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 58.9815 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2370.8440 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 23971.9512 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 134783.8281 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 417875.7188 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 983748.5000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2194793.5000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4114490.5000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7238609.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 10955242.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17132686.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 24705976.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 35139520.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 48019164.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 61740000.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 79896664.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 105783704.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 129208288.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 160214640.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 195800832.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 191076336.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 41.0159 - accuracy: 0.8778\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1485.8353 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13469.9287 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 56284.5742 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 189504.5156 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 504035.9688 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 958537.6250 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1928050.8750 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3092202.7500 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5146988.5000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7733047.5000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11020508.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15190967.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 20934208.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 28192316.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36306980.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 48020708.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 57855184.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 73114480.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 90492320.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 83984048.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 30.5292 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 949.4515 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8976.8975 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 46437.0820 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 144184.6875 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 370769.9688 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 812737.9375 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1445259.1250 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2499550.7500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3938400.7500 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6039312.5000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8918842.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12061421.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 16731810.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 21208204.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 28001742.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 36043844.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 45638296.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 57532444.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 67178736.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 98027816.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 39.7006 - accuracy: 0.8838\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1767.3265 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17016.2832 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 69133.0547 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 209400.5000 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 498394.0000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1086199.6250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2079564.7500 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3383101.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5379582.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8791002.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11977425.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16839602.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 23032278.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 30732852.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 39754840.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 50094112.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 63903336.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 76778264.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 94726776.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 92883768.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 93.1041 - accuracy: 0.8753\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 4481.8511 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 45111.9570 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 202784.6562 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 759123.3750 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1722601.6250 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3330543.5000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6319803.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11177617.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 17411426.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26580020.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 37832948.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 52757488.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 71532840.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 96831776.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 125014688.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 156488704.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 191841280.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 254006048.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 305710880.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 282731712.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 77.1231 - accuracy: 0.8893\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3204.0774 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 37092.5664 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 161820.0312 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 503036.4688 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1393947.3750 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2738588.7500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4986242.5000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 8724427.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 13240777.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19875360.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 29575172.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40629828.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 57256300.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 74861776.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 99689048.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 125724584.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 152903008.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 196804656.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 232737200.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 334800960.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 143.9460 - accuracy: 0.8814\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5725.1045 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 50330.5625 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 254776.8438 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 809320.1250 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1958864.1250 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4443226.0000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7431857.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12827538.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 22242138.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 31556756.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 47946940.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 66266644.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 88766168.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 116981696.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 149159248.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 190155136.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 241302688.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 291110464.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 363246688.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 350958592.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 39.9755 - accuracy: 0.8768\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1526.2516 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16097.6934 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 77591.9531 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 248170.3750 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 582661.3750 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1257354.2500 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2436774.5000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4257372.5000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6306622.5000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10051064.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14408225.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 19827390.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 27433656.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 38095580.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 47234280.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 60168528.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 79191072.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 97236496.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 116761880.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 108918096.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 11ms/step - loss: 32.9537 - accuracy: 0.9002\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1596.0015 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15667.1895 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 74127.3984 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 238525.9062 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 613351.0625 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1365942.7500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2535585.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4372580.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6916771.5000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10580450.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15302171.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 21883748.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 30449834.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 41397232.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 52038968.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 67374232.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 84624432.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 104907472.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 126995176.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 182697872.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 32.3926 - accuracy: 0.8833\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1059.6215 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9949.6094 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 50696.4883 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 163308.4375 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 388051.0938 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 842291.5000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1587118.1250 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2982708.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4873478.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7303959.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10999960.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15516351.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 20770304.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26755214.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36427120.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 44815888.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 56490984.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 70085280.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 84849280.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 83408064.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 81.4283 - accuracy: 0.8733\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5982.8423 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 56420.7578 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 356577.0938 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1045255.8125 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2535196.2500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5563523.5000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 10758797.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 16682072.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26663014.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 42548372.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 60650284.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 86971696.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 118260728.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 157283824.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 204757056.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 254363968.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 322752768.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 393815168.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 473106560.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 443258368.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 150.7876 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 8144.8608 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 91527.5156 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 475666.4688 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1499119.8750 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3459349.0000 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8053096.5000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14345279.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 23451144.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 39096872.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 57281200.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 86260312.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 122418960.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 160726560.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 218502432.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 278007648.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 355591648.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 446908832.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 554964352.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 664925568.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 962855808.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 134.9357 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 6758.0146 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 66585.0156 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 298767.2188 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 967711.1250 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2451025.7500 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4867716.0000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 10305164.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 15717265.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 25257048.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 40594012.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 57111000.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 75745976.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 105548400.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 143653568.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 190373552.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 241325664.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 297575168.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 368478816.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 443075264.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 430260064.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 56.8661 - accuracy: 0.8753\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2642.8423 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 29942.8125 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 157594.3281 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 484655.0938 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1316967.7500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2597286.5000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5115200.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8751349.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13425785.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 20453476.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 30708328.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 42373408.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 56487576.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 75601024.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 96561280.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 123573304.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 156332720.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 192335648.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 233092720.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 220941200.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 54.0753 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2484.0430 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 28106.5059 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 142970.4375 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 451310.2500 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1133638.3750 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2230174.5000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4369879.5000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7231633.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11826878.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17620780.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 25248622.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 34263384.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 46967492.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 63697796.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 82600392.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 103147080.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 129629384.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 159776720.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 188231872.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 271941888.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 87.9799 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3778.9368 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 44042.4180 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 184354.0938 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 716397.0625 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1528677.8750 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3244042.7500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5857959.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10142946.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 16805506.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 25352206.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36803764.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 50640536.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 68629176.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 92200592.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 120534984.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 150685488.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 191091504.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 238592272.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 282124416.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 280556416.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 12ms/step - loss: 154.4390 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 8156.9121 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 88501.4844 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 469292.2188 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1499412.5000 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3749146.0000 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 8274584.0000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 16085037.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 27495910.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 43458284.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 63900360.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 94516368.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 136335152.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 185201680.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 239139504.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 315544832.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 404914112.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 519603776.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 625000832.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 760022208.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 701557056.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 182.1742 - accuracy: 0.8858\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 12514.6094 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 134323.8125 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 612542.4375 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 1882174.0000 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 4348846.0000 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 9227066.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 19299034.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 32307368.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 55907900.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 82852344.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 121436576.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 171886432.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 232398560.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 306446464.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 410585792.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 518426816.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 653922816.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 791704896.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 971691200.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 1382296064.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 237.6045 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 14032.5117 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 158948.7188 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 742387.7500 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 2395844.2500 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 6082066.5000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 13300498.0000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 24575086.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 40645056.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 66175492.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 96350816.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 136237296.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 192794096.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 265516192.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 348271072.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 436182272.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 572124352.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 737701632.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 913027520.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 1109977600.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1070832448.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 82.2034 - accuracy: 0.8808\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5014.3550 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 49712.5312 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 251358.7500 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 736830.0000 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2012647.7500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3631667.7500 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6995960.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11765739.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19239288.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 28843314.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 40537072.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 60379752.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 79067936.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 110654800.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 140320720.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 174880656.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 223862272.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 290075104.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 333847904.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 316397216.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 83.9781 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 4907.7725 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 54057.1211 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 288017.9375 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 985895.8125 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2259714.7500 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4709999.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9018499.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 15204681.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 23302660.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 36315868.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 51977284.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 68749896.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 95900672.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 122471360.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 160961504.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 208412064.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 257134256.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 317608352.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 390357920.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 557678848.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 113.2439 - accuracy: 0.8814\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5461.6509 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 55500.7891 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 239386.2500 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 761443.0000 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 2031202.3750 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4145248.7500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 7539309.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14001667.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 21245172.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 32285478.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 45963768.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 64005492.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 90190432.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 114780288.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 151432912.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 190945200.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 238014704.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 291021856.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 358261184.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 351988032.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 13.6326 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 191.9186 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1009.5682 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2847.8557 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 6765.4146 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 12781.2090 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 22218.4199 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 33262.8984 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 47483.9141 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 66787.7812 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 91191.2891 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 115990.8438 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 148934.8906 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 185764.5312 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 231868.2188 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 277365.1875 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 327930.1250 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 383314.4062 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 452931.9375 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 516637.4375 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 475895.7812 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 18.2453 - accuracy: 0.9002\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 214.5604 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1022.3487 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2823.5293 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6209.3428 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 12964.0957 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23045.4023 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 35349.5000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 52885.8320 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 75684.1719 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 105969.7344 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 135108.3125 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 179357.6562 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 222805.6719 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 286922.0625 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 349647.0312 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 428294.3125 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 506627.0625 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 595013.5000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 695752.2500 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 968715.1250 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 14.8540 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 230.7272 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1049.4326 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3200.7749 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6894.6240 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14257.9775 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21732.9414 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 34632.9258 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 49006.6680 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 71988.5703 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 95277.3750 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 122370.5547 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 154528.2188 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 199891.0625 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 242705.7500 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 293728.4062 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 354440.2500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 410855.3750 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 474879.3750 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 562798.6250 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 534239.5625 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 10.6275 - accuracy: 0.8753\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 89.3839 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 488.3871 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1226.2037 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2700.0769 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 4682.4863 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8166.6504 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 11877.8545 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 17884.1602 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 24317.8027 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 33844.7227 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 43659.0156 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 55030.0234 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 68895.6484 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 87915.8047 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 106858.8906 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 127618.7969 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 151148.6406 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 175349.3281 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 204445.6406 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 185079.1094 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 9.7721 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 108.0498 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 574.4598 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1550.9767 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 3140.3542 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6110.7744 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 10161.0488 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 15794.8594 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 23558.3047 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 33896.7188 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 47350.3672 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 62933.2500 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 80142.2109 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 103877.0938 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 124801.4531 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 152189.0938 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 181873.3906 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 217821.8750 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 246944.8281 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 294965.9688 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 408574.9688 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 8.0461 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 110.0897 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 431.8059 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1292.9209 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3016.6521 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5803.6431 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9573.7725 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14158.2891 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 21782.3711 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 29886.3145 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 37584.0039 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 50133.3203 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 64471.3555 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 82191.1250 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 100169.7734 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 122879.6875 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 144530.2500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 170477.0938 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 203603.6406 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 241170.6094 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 227314.6094 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 8ms/step - loss: 27.0283 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 398.5038 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2569.6238 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7257.7251 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 17218.5215 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 33670.7500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 57924.8086 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 92253.9844 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 134882.6562 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 191095.6250 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 254476.7969 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 337799.4375 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 437947.7812 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 554815.9375 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 678337.1875 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 846302.1875 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 997724.1875 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1184307.2500 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1386221.5000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1615273.3750 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1478972.5000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 22.3097 - accuracy: 0.8858\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 373.9745 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2256.8411 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7752.8418 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17826.6387 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 33487.7422 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 59139.0742 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 90008.7969 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 142917.0781 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 212469.3438 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 286002.7188 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 386258.9688 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 479354.5625 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 624634.3125 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 762050.8750 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 939001.0625 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1104213.3750 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1344126.7500 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1569129.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1800501.2500 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2524143.5000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 22.1625 - accuracy: 0.8853\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 352.1588 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1807.9792 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6176.5063 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12507.5391 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 25006.3809 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 43332.1055 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 74600.7891 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 109453.1562 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 144668.3281 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 198893.6094 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 269604.9375 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 353278.2812 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 446210.9688 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 556307.2500 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 681321.7500 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 801851.0625 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 936728.1875 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1115271.5000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1287127.3750 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1219793.8750 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 8.8208 - accuracy: 0.8733\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 166.0650 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 778.9676 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2502.1624 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6399.8945 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12703.3857 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 22922.9492 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36906.3164 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 53378.9766 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 75408.3281 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 101560.0391 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 133121.2656 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 174548.3906 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 209399.1094 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 263384.1562 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 320710.6562 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 377254.0625 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 438752.4688 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 533240.3125 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 614582.5625 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 555607.8125 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 9.9241 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 140.6021 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 807.2401 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2434.6013 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 5881.9077 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 10853.7305 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 18417.4863 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 30510.6484 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 46730.6914 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 64238.4297 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 90365.9453 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 115687.2812 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 150060.7500 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 189444.7344 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 233326.6094 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 279831.7812 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 338719.3750 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 403445.1562 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 468208.8438 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 547783.3125 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 761998.1875 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 16.0980 - accuracy: 0.8853\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 196.2907 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 811.2371 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2677.6860 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6774.6494 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 11864.0107 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 20410.9922 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 30498.7656 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 45363.9727 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 66635.4531 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 88094.8594 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 114009.2656 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 142548.8750 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 180087.1875 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 223701.3750 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 273659.7188 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 317538.3750 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 378701.7500 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 439289.4062 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 508987.5000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 488585.6875 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 31.1561 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 555.7684 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3244.5513 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9348.1572 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 22021.6621 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 41583.5273 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 74135.8047 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 116167.5781 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 182470.8594 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 250213.7188 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 332248.0938 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 459253.0312 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 615722.0625 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 750630.9375 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 967057.5000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1178545.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1393122.1250 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1689449.7500 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1959166.2500 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2270049.7500 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2078628.1250 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 32.4814 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 523.4305 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3061.1829 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9689.1553 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 21513.0371 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40333.8555 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 65714.6250 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 103718.5781 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 157364.7656 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 208486.6406 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 291850.1250 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 386224.0938 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 509706.8750 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 609161.1875 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 751270.3750 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 910164.5625 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1069281.2500 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1263951.8750 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1504816.3750 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1735596.8750 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2453903.2500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 36.0691 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 638.2022 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3932.5388 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 11559.2402 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26143.6504 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 52664.8477 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 85297.3828 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 141399.3906 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 208853.3125 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 282229.7188 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 402732.2188 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 533096.8750 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 678577.8125 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 852246.5000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1087144.7500 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1340066.1250 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1541774.1250 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1837689.2500 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2193529.5000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2583573.5000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2422693.5000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 39.7354 - accuracy: 0.8753\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 558.4869 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2545.2173 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7357.5483 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 16493.8457 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 32956.4102 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 56576.5273 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 82991.1641 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 127667.0781 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 185137.7969 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 240912.3281 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 335360.3125 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 427953.3125 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 535064.1875 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 660256.2500 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 790480.3750 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 961231.2500 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1116416.6250 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1283082.7500 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1502943.7500 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1386407.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 16.0717 - accuracy: 0.9012\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 299.1043 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1603.6996 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4569.3833 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 10676.5752 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 21031.5918 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 36508.8242 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 56637.2148 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 82546.6641 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 113758.3125 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 152559.5156 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 200197.6719 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 267433.4062 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 331484.5000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 404009.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 499806.2188 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 590208.5000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 720395.0625 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 811470.0625 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 939776.5625 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1325317.7500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 26.0236 - accuracy: 0.8848\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 355.7299 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2042.9033 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6447.6821 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14727.0918 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26632.4082 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 49979.8086 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 79222.3750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 116307.7188 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 156792.2500 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 223147.3594 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 286018.6562 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 355464.6875 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 454272.4688 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 572109.6250 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 696911.5625 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 792248.0625 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 968896.7500 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1156000.5000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 1321402.6250 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1254700.5000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 25.7284 - accuracy: 0.8768\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 470.1143 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2739.6479 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8864.1543 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17031.1738 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 34468.8945 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 64057.7891 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 98700.6641 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 149385.6875 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 199060.2656 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 262062.7969 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 358898.6562 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 456835.8125 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 548121.8750 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 682117.2500 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 870553.7500 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1005750.7500 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1192804.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1402090.3750 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1645703.8750 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1475344.8750 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 34.7813 - accuracy: 0.8888\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 426.1038 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2112.5505 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5688.5923 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14064.8730 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26785.6406 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 44930.4961 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 68695.8203 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 105370.8438 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 142898.2188 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 205116.1719 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 263212.8750 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 340070.6875 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 422646.9375 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 519754.9062 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 629031.7500 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 745038.5000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 900601.6250 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1079609.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1235898.3750 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1723492.7500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 22.3707 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 341.4392 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1979.8944 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7389.9937 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 17290.6816 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 32476.5898 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 61681.0117 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 95227.3906 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 139215.5781 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 202117.8750 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 274149.8750 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 371004.5625 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 485072.4062 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 604832.8125 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 746597.1250 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 916975.5000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1081046.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1288570.6250 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1488390.1250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1698191.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1635974.3750 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 13.5962 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 247.0784 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1250.6346 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3694.6375 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 8933.3516 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 17760.2461 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 26910.6289 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 41870.6250 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 63515.0391 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 87574.7656 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 117737.2969 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 152014.7031 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 204494.2656 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 240366.5469 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 298749.5938 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 363910.5000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 426051.0938 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 515112.6875 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 600064.9375 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 691629.7500 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 636406.0625 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 13.3664 - accuracy: 0.9007\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 228.0729 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1053.6359 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3006.3987 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6875.9316 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 12685.5479 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 22052.2969 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 37775.2852 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 55043.9258 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 74562.9453 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 105394.3828 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 138823.7188 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 177112.0469 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 229549.3906 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 278732.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 335488.9688 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 403655.5625 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 480390.8750 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 560135.8125 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 636368.9375 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 893647.5625 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 17.6489 - accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 248.3783 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1010.1973 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 3581.4041 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7646.9517 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 15866.3945 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 30068.2363 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 44874.7969 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 64565.2695 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 91854.7266 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 117410.6172 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 159788.7812 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 204715.1250 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 256139.1094 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 312170.2188 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 367183.1875 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 453693.9688 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 553020.9375 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 648405.5000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 731029.1875 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 697872.3125 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 38.5794 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 828.2542 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4891.1025 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15146.8125 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 39534.4961 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 72120.3281 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 115461.5000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 188551.8594 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 258388.0312 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 383333.0625 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 492522.8750 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 694264.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 881169.3125 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1068363.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1348822.1250 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1600541.3750 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1967914.7500 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2328558.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2691000.7500 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3152131.5000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2842763.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 35.0896 - accuracy: 0.8933\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 879.7662 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4202.2588 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11110.3984 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 27407.4863 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 55668.0859 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 93069.3672 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 147190.9375 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 216207.7188 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 322659.5625 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 422024.3438 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 544042.1250 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 704965.4375 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 897479.5000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1120705.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1361415.6250 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1644811.7500 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1958735.5000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2269706.5000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 2658654.2500 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 3715690.2500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 39.8954 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 678.8585 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4606.7729 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 16281.3545 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 34477.3125 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 73411.6016 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 112298.5078 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 201466.5625 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 285939.8125 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 397899.0938 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 557818.8125 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 701966.0625 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 892591.5625 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1141254.1250 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1405861.5000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1651863.1250 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2090146.2500 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2432142.5000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2844325.5000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 3359976.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 3196656.7500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 34.0322 - accuracy: 0.8658\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 404.6765 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2257.6619 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 6470.2002 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13661.1094 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26851.0703 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 45643.2578 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 69669.6016 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 106949.9062 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 148037.2969 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 193291.0625 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 270999.4688 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 343554.8125 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 425232.3750 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 519989.0312 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 643355.3750 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 766846.9375 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 905175.2500 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1080032.3750 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1234490.2500 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1119531.8750 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 28.2573 - accuracy: 0.8783\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 424.6564 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2426.0525 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 6867.9434 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15106.0703 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 29413.8984 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 53431.8945 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 79741.7109 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 121195.4609 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 174548.2656 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 223830.2969 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 296085.1562 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 372061.9688 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 476333.9688 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 596574.2500 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 716670.3125 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 848435.8750 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1001593.3125 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1163329.6250 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1341961.8750 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1896289.7500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 21.2027 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 294.5467 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1593.7308 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 5078.0879 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 11283.4443 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 22264.2363 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 41511.3711 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 63392.2969 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 86722.4609 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 129700.7031 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 175039.8438 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 235841.1875 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 291012.7188 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 367535.5625 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 458366.8438 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 552308.2500 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 649373.5000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 787063.3750 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 908424.7500 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1065196.7500 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1019553.9375 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 78.4130 - accuracy: 0.8738\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1938.7168 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9805.0352 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 28648.5723 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 67540.6719 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 130048.2891 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 225670.0938 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 351932.3125 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 512558.2812 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 705738.9375 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 960893.3750 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1252683.1250 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1685047.1250 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2134936.5000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2576558.5000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3083749.2500 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3697074.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4391034.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5082203.5000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5964529.5000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 5416178.5000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 72.7530 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1527.9491 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8492.9668 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 28655.1699 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 66174.0469 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 133437.9844 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 223326.3281 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 338905.7812 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 521375.7500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 756088.1250 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 994154.0625 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1286624.6250 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1621489.8750 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2077628.6250 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2470169.5000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3131424.7500 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3617365.2500 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4421238.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5183027.5000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6059822.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 8372940.5000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 70.1168 - accuracy: 0.8719\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1137.6306 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 6278.8433 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 20395.5488 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 45045.6758 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 98938.5000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 180448.7188 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 281124.9062 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 419239.4688 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 587105.6875 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 792981.8750 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1053185.8750 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1346950.2500 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1749234.1250 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2093962.7500 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2579251.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3149090.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3692723.5000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4238806.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5053813.5000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 4789125.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 44.6799 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 815.3409 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4409.0254 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 14164.1855 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 27669.3984 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 54830.5352 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 93298.6875 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 157714.3125 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 217099.8125 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 313270.0312 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 429542.7812 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 568077.8125 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 716610.8750 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 890063.5625 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1113920.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1335760.3750 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1648074.5000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1920672.1250 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2290952.5000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2699461.2500 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2450003.5000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 52.8112 - accuracy: 0.8913\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 906.9052 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4430.1382 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13206.5898 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 32273.4629 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 61142.9258 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 103862.8047 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 164405.0781 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 228403.1094 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 323951.9688 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 441403.9375 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 584193.3125 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 735236.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 937191.7500 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1159099.6250 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1406872.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1698724.7500 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2024899.3750 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2307754.7500 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2718909.5000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 3775002.2500 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 24.9928 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 762.2909 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4150.6221 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12761.1943 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 27283.3438 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 54689.9297 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 85911.8906 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 138106.8281 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 202865.9219 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 276706.4688 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 380350.0312 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 484140.5000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 624418.3750 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 761149.1875 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 977141.7500 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1191170.7500 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1416846.6250 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1700507.7500 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1922713.1250 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2191111.7500 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2127697.2500 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 18.0789 - accuracy: 0.8888\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 768.9990 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6227.1123 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 28256.6113 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 101558.6016 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 255373.2656 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 498707.6562 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 969249.2500 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1658113.6250 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2611710.5000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3988402.2500 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5648837.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8357003.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11047516.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14770761.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 18991668.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 24241194.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 30300606.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 36967024.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 45631364.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 42656200.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 29.8138 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 764.6935 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6012.0918 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 27147.6973 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 84796.3906 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 195585.8125 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 404611.9375 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 779147.5625 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1315534.1250 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2155904.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3156732.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 4808738.5000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 6398600.5000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 9198793.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 12050389.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 15606387.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 20097424.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 25116876.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 31982168.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 37600304.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 54548204.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 10ms/step - loss: 27.4377 - accuracy: 0.8774\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 754.9412 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 6836.8716 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 31734.2812 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 99146.3359 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 259089.1562 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 517520.6250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 994654.9375 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1788465.1250 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2904213.2500 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4234760.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6211864.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8720773.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12118988.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 16416414.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 20593194.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26568406.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 33638196.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 41943532.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 49936860.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 49508160.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 20.7079 - accuracy: 0.8828\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 557.6506 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4963.4663 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 21127.3301 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 59701.4375 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 158904.4688 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 339455.8125 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 623612.3125 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1023009.8750 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1633805.2500 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2272332.7500 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3479042.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4993521.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6775740.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 8898533.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11179802.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 14541844.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17935550.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 22324912.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 27557212.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 25412768.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 15.9067 - accuracy: 0.8803\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 430.7992 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4644.6426 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 26156.8535 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 66764.1406 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 189220.1406 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 357629.1562 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 683670.4375 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1158620.6250 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1775993.5000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2670736.2500 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3719096.7500 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5198787.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 7035340.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8894698.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11873685.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15225979.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 18932220.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 23184996.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 28197658.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 40491380.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 13.2605 - accuracy: 0.8779\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 382.3134 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3394.6719 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 18584.9922 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 56620.1328 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 127747.3125 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 281890.2188 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 542457.8750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 854443.8125 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1317585.6250 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 2125968.2500 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2914418.5000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4167492.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5825374.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7713530.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 10093032.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12560302.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 15897368.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19365548.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 24140592.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 23195568.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 53.4006 - accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1774.7825 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15531.0117 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 75522.4609 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 281042.9062 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 654643.0000 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1282858.1250 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2379558.2500 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4107416.5000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 6571804.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9783696.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13838428.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 19329968.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26978496.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 34116688.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 44078292.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 55165300.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 70816464.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 88183848.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 105489336.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 97771248.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 27.1983 - accuracy: 0.8893\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 787.7661 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9161.6992 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40416.5508 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 142611.6562 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 323616.0312 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 759541.3125 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1362045.8750 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2307615.7500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3711132.5000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5585876.5000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8193800.5000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 11218772.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 15692649.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 20860904.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 27015824.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 35396280.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 43662840.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 55577508.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 68130080.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 97685984.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 43.8454 - accuracy: 0.8858\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1540.2168 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 16352.7852 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 75694.2344 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 234921.4219 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 603062.3125 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1318951.7500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 2358139.7500 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4233461.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6622119.5000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9627109.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14344537.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 20673256.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26936926.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 37461636.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 48071056.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 60114556.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 77084456.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 96253176.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 114696272.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 112372192.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 24.9955 - accuracy: 0.8628\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 953.5195 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 7975.4146 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 33230.7188 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 109618.8906 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 251215.9531 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 498810.5312 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 921422.8125 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1545883.5000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 2335453.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3481109.2500 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5009939.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 7132633.5000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9358114.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12722121.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 16170548.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 20775062.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26003084.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 32153470.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 38349880.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 35627608.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 19.9778 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 829.5046 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7509.4517 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 37889.7227 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 122190.9766 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 294687.8750 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 637224.5000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1134207.7500 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1968713.8750 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3104094.7500 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 4758963.5000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 7037887.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9384532.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12928036.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 17322232.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 22555132.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 28656554.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 35434968.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 42831580.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 54223764.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 78108896.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 17.1815 - accuracy: 0.8749\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 444.2395 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5720.5820 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 22691.9727 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 72823.6719 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 157116.6250 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 331998.0000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 588033.8750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1020959.7500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1542714.6250 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 2333743.2500 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3453654.5000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 4715786.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6431747.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8602452.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11065880.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 13692421.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 17171266.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 21549288.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 26007946.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 25507176.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 62.9302 - accuracy: 0.8748\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2346.0378 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 24597.9785 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 115295.7188 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 374407.0625 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 847193.0000 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1936296.5000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3936650.7500 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6508740.5000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 10778369.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15199980.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 22443500.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 31589484.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 42224016.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 55206076.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 73864656.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 93136240.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 114596320.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 142064256.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 175436720.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 161406256.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 67.6845 - accuracy: 0.9007\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 2632.4734 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 24768.4961 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 109012.0469 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 394240.2812 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 921260.5000 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1757604.3750 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3495327.2500 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5884747.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 9312399.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 13503836.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19662082.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 26901648.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 35259352.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 49334872.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 62260692.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 80212848.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 100933120.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 123411208.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 149855104.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 215235600.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 67.1394 - accuracy: 0.8714\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2517.8181 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 22934.3086 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 105219.5469 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 402517.5625 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 979906.5625 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1833443.8750 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3173742.7500 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5747729.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9441191.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 13815379.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 20193088.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 28714258.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 37671388.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 50798792.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 65753596.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 84405416.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 103934976.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 132347384.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 155305920.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 153891728.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 33.9384 - accuracy: 0.8743\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 865.4802 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 8313.3105 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40219.5469 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 136835.2969 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 333359.3750 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 710012.7500 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 1369806.6250 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2474274.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3843195.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5467875.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8351039.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11443231.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 15718965.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 20043256.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 26550914.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 33048606.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 42475180.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 52432228.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 62002036.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 57584060.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 39.7865 - accuracy: 0.8838\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1339.4805 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 16404.2891 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 75358.1562 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 215679.7500 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 567271.5625 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 990093.1875 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1990681.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3271860.7500 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5086050.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 7681187.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11300204.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 16091031.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 21359750.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 27280708.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 36121420.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 46771136.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 57239052.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 71151176.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 86647864.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 123316312.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 51.8796 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1329.5768 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 10453.8613 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 48036.3555 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 140920.4531 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 347339.4062 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 733640.3750 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1369783.8750 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2482520.7500 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3760886.2500 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 6038785.5000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8730769.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12386884.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 15900288.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 21284644.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 28246056.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 35194664.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 43053432.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 54895556.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 66177900.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 64351668.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 87.7295 - accuracy: 0.8783\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3593.7107 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 35296.2617 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 174331.3125 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 574168.5625 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1338460.3750 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2769920.5000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4788017.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9044225.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 14042001.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 20538312.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 29973662.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 42009508.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 59657584.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 77832440.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 100455744.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 127845592.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 161940224.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 200850128.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 248665552.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 230121056.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 132.3590 - accuracy: 0.8863\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4782.5020 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 42478.4766 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 198246.4062 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 630156.7500 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1458390.3750 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3243717.2500 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6314585.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 9646901.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15869431.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 23370950.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 34694720.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 48281556.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 65921652.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 87435168.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 112732816.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 139586256.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 174296064.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 219404080.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 261150112.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 374605984.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 95.0088 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5202.6616 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 54220.8594 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 285402.4375 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 814961.3125 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2106739.0000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4493979.0000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 8824725.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 14404136.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 52680476.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 71298568.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 97255056.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 129896728.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 169036160.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 211140768.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 267079328.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 320765824.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 389758464.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 382475776.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 47.2164 - accuracy: 0.8793\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1770.4381 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 18281.8281 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 76591.2969 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 244206.7969 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 669534.6250 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1400217.6250 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2730911.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4465875.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7392200.5000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 10812597.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 16296873.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 22529448.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 30662004.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 41006936.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 52639076.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 68589984.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 86686088.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 108014488.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 129517712.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 121503656.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 44.2064 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1950.4027 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 21451.3789 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 107773.6719 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 334578.6250 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 836708.6875 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1643789.6250 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2913764.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 5396612.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8208262.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 12256805.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 17836460.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 24340336.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 32796276.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 43203156.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 53564116.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 68998696.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 86660104.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 104936080.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 127438696.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 182413424.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 27.2936 - accuracy: 0.8719\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1215.4153 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 15154.6494 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 71334.1562 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 219115.7969 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 561875.3125 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1231813.1250 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2189258.7500 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3932348.5000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 5827679.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 9329142.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13649773.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 18780384.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 24822288.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 34073124.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 43256252.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 55884860.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 68814872.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 84964144.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 104781488.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 100399984.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 12ms/step - loss: 153.4612 - accuracy: 0.8753\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 5576.4219 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 64077.5352 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 346983.1562 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1003518.6875 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3016275.2500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6153000.0000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 11464973.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 19588672.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 31709550.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 48276960.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 68664160.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 98311408.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 132236264.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 173754720.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 230030448.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 288536864.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 361389792.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 446843296.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 547815360.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 507226784.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 161.1606 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 8196.4951 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 85877.3438 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 406447.2188 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1395369.3750 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 3441850.5000 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 7158476.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 14162208.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 22598784.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 38149148.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 56690424.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 84867744.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 116476232.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 160030016.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 209440112.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 275709120.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 337758048.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 433670016.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 514750720.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 652456448.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 935109120.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 11ms/step - loss: 131.9762 - accuracy: 0.8744\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 7038.9351 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 68450.7812 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 307787.8438 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1032414.6875 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2581897.7500 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 5364498.5000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 9660170.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 16694530.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 27005276.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 39190176.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 59821776.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 84510432.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 112060088.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 156273616.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 205958832.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 259609440.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 320359936.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 403730112.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 495690880.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 490998368.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 63.7284 - accuracy: 0.8718\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2885.8523 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 26046.7129 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 132056.8750 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 440268.0938 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 977685.2500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2164337.7500 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3868013.7500 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6616672.5000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 10695673.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 15725983.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 21901910.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 31310584.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40988688.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 55121256.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 71056832.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 87364848.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 113341632.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 134493552.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 171167376.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 157663744.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 9ms/step - loss: 39.2416 - accuracy: 0.8873\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2429.5447 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 29220.4746 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 134936.6875 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 533534.3125 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1196372.3750 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2700817.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 4855549.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 8368100.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12776057.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 19673968.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 28534694.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 40354256.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 51671680.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 69047880.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 94061824.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 116018088.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 143403472.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 176351152.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 213384320.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 304753056.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 74.4442 - accuracy: 0.8754\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3069.8638 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 32201.3926 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 142562.3750 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 554902.5000 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1304796.2500 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 2699160.7500 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4859294.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 8331676.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13033843.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 20161550.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 27310156.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 40716776.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 52887812.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 71013192.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 90939408.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 117797024.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 148548128.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 182152832.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 214705328.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 213950080.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 12ms/step - loss: 172.5893 - accuracy: 0.8738\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 6903.1304 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 78701.6797 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 332741.7812 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 1190152.2500 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 3225072.7500 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 6236914.5000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 11820741.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 19925802.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 32649636.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 50133564.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 71127968.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 99583872.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 141469808.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 191338208.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 240850128.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 301261376.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 374072224.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 472185152.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 574243648.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 534700960.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 12ms/step - loss: 218.3398 - accuracy: 0.8903\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 10305.3096 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 116961.1406 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 522019.5625 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1588019.0000 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 4068181.0000 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 8322315.5000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 16679568.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 26654546.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 42511356.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 64022748.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 94371528.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 131067064.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 183505840.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 240140464.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 305542912.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 397039040.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 500946048.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 627569280.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 771352064.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1105207936.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 12ms/step - loss: 198.4202 - accuracy: 0.8759\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 11162.4121 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 117258.3672 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 642692.6250 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 1880796.7500 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 4980411.0000 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 9938650.0000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 19453110.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 34763452.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 52319896.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 82635872.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 116401440.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 164214304.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 222316112.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 304362272.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 382851872.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 491039840.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 614198208.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 766452096.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 907416576.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 890746880.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 82.8907 - accuracy: 0.8778\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4059.7751 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 50419.2031 - accuracy: 0.8888\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 232929.6719 - accuracy: 0.8888\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 759316.2500 - accuracy: 0.8888\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1776476.6250 - accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3702683.0000 - accuracy: 0.8888\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 7260031.0000 - accuracy: 0.8888\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 12248237.0000 - accuracy: 0.8888\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 18181062.0000 - accuracy: 0.8888\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 29525394.0000 - accuracy: 0.8888\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 42990284.0000 - accuracy: 0.8888\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 61671320.0000 - accuracy: 0.8888\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 84374568.0000 - accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 111684416.0000 - accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 144534576.0000 - accuracy: 0.8888\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 182544512.0000 - accuracy: 0.8888\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 229202960.0000 - accuracy: 0.8888\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 282356448.0000 - accuracy: 0.8888\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 332747200.0000 - accuracy: 0.8888\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 308179968.0000 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 75.6473 - accuracy: 0.8878\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3471.6614 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 38352.8086 - accuracy: 0.9017\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 208440.4375 - accuracy: 0.9017\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 674081.9375 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1814871.3750 - accuracy: 0.9017\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3777889.0000 - accuracy: 0.9017\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 6595515.0000 - accuracy: 0.9017\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 11237446.0000 - accuracy: 0.9017\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 18123246.0000 - accuracy: 0.9017\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 27946522.0000 - accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 41386892.0000 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 55606944.0000 - accuracy: 0.9017\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 76973936.0000 - accuracy: 0.9017\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 100659320.0000 - accuracy: 0.9017\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 128232592.0000 - accuracy: 0.9017\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 163594976.0000 - accuracy: 0.9017\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 211153600.0000 - accuracy: 0.9017\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 251986576.0000 - accuracy: 0.9017\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 317880992.0000 - accuracy: 0.9017\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 452200672.0000 - accuracy: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 59.7110 - accuracy: 0.8838\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 3337.3977 - accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 42823.4336 - accuracy: 0.8893\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 237133.4375 - accuracy: 0.8893\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 816871.0000 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1923856.3750 - accuracy: 0.8893\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 4339252.5000 - accuracy: 0.8893\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 8447819.0000 - accuracy: 0.8893\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 13845253.0000 - accuracy: 0.8893\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 21566346.0000 - accuracy: 0.8893\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 33043098.0000 - accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 48266300.0000 - accuracy: 0.8893\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 71489552.0000 - accuracy: 0.8893\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 94729976.0000 - accuracy: 0.8893\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 125174984.0000 - accuracy: 0.8893\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 160578352.0000 - accuracy: 0.8893\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 207833216.0000 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 251222048.0000 - accuracy: 0.8893\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 312620320.0000 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 383243392.0000 - accuracy: 0.8893\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 372896608.0000 - accuracy: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "94/94 [==============================] - 2s 6ms/step - loss: 25.8408 - accuracy: 0.8850\n",
            "Epoch 2/20\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 439.9984 - accuracy: 0.8933\n",
            "Epoch 3/20\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 1750.1072 - accuracy: 0.8933\n",
            "Epoch 4/20\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 5965.9521 - accuracy: 0.8933\n",
            "Epoch 5/20\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 13529.9219 - accuracy: 0.8933\n",
            "Epoch 6/20\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 23884.6016 - accuracy: 0.8933\n",
            "Epoch 7/20\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 39861.1953 - accuracy: 0.8933\n",
            "Epoch 8/20\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 64049.5430 - accuracy: 0.8933\n",
            "Epoch 9/20\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 91426.7031 - accuracy: 0.8933\n",
            "Epoch 10/20\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 126275.6953 - accuracy: 0.8933\n",
            "Epoch 11/20\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 176241.8125 - accuracy: 0.8933\n",
            "Epoch 12/20\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 237147.7031 - accuracy: 0.8933\n",
            "Epoch 13/20\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 291126.9688 - accuracy: 0.8933\n",
            "Epoch 14/20\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 364752.8125 - accuracy: 0.8933\n",
            "Epoch 15/20\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 454705.2188 - accuracy: 0.8933\n",
            "Epoch 16/20\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 521596.6875 - accuracy: 0.8933\n",
            "Epoch 17/20\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 629687.0625 - accuracy: 0.8933\n",
            "Epoch 18/20\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 746220.0000 - accuracy: 0.8933\n",
            "Epoch 19/20\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 851509.3750 - accuracy: 0.8933\n",
            "Epoch 20/20\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 1009786.3750 - accuracy: 0.8933\n",
            "Best parameters:  {'kernel_size': (3, 3), 'learning_rate': 0.001, 'num_dense_layers': 1, 'num_dense_units': 32, 'num_filters': 8, 'pool_size': (2, 2)}\n",
            "Best accuracy:  0.8932872215906779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOOMfeUb8CJm"
      },
      "outputs": [],
      "source": [
        "#Creating CNN from Scratch\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(4,4),padding=\"Same\",activation=\"relu\",input_shape=(75,75,3)))\n",
        "model.add(Conv2D(filters=32,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(filters=64,kernel_size=(4,4),padding=\"Same\",activation=\"relu\")) \n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(filters=64,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(filters=64,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=128,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(filters=128,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(filters=128,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256,activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(9,activation=\"softmax\"))\n",
        "\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-4 ),\n",
        "    loss =  keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics = ['accuracy']\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Abz-PmCD84RH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa75e33-6374-4472-866a-3f68c8b7c3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 1.7278 - accuracy: 0.3647\n",
            "Epoch 1: val_loss improved from inf to 1.88854, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 186s 117ms/step - loss: 1.7278 - accuracy: 0.3647 - val_loss: 1.8885 - val_accuracy: 0.3598 - lr: 1.0000e-04\n",
            "Epoch 2/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 1.3223 - accuracy: 0.5364\n",
            "Epoch 2: val_loss improved from 1.88854 to 1.47786, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 156s 105ms/step - loss: 1.3223 - accuracy: 0.5364 - val_loss: 1.4779 - val_accuracy: 0.5038 - lr: 1.0000e-04\n",
            "Epoch 3/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 1.0796 - accuracy: 0.6269\n",
            "Epoch 3: val_loss improved from 1.47786 to 1.22954, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 158s 107ms/step - loss: 1.0796 - accuracy: 0.6269 - val_loss: 1.2295 - val_accuracy: 0.5683 - lr: 1.0000e-04\n",
            "Epoch 4/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.9283 - accuracy: 0.6741\n",
            "Epoch 4: val_loss improved from 1.22954 to 1.19906, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 167s 113ms/step - loss: 0.9283 - accuracy: 0.6741 - val_loss: 1.1991 - val_accuracy: 0.5777 - lr: 1.0000e-04\n",
            "Epoch 5/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.8292 - accuracy: 0.7076\n",
            "Epoch 5: val_loss improved from 1.19906 to 0.97686, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 168s 114ms/step - loss: 0.8292 - accuracy: 0.7076 - val_loss: 0.9769 - val_accuracy: 0.6698 - lr: 1.0000e-04\n",
            "Epoch 6/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.7376 - accuracy: 0.7411\n",
            "Epoch 6: val_loss improved from 0.97686 to 0.78389, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 164s 111ms/step - loss: 0.7376 - accuracy: 0.7411 - val_loss: 0.7839 - val_accuracy: 0.7369 - lr: 1.0000e-04\n",
            "Epoch 7/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.6559 - accuracy: 0.7677\n",
            "Epoch 7: val_loss improved from 0.78389 to 0.73268, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 176s 119ms/step - loss: 0.6559 - accuracy: 0.7677 - val_loss: 0.7327 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
            "Epoch 8/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.7853\n",
            "Epoch 8: val_loss improved from 0.73268 to 0.66981, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 159s 107ms/step - loss: 0.6050 - accuracy: 0.7853 - val_loss: 0.6698 - val_accuracy: 0.7644 - lr: 1.0000e-04\n",
            "Epoch 9/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.8040\n",
            "Epoch 9: val_loss improved from 0.66981 to 0.64526, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 160s 108ms/step - loss: 0.5548 - accuracy: 0.8040 - val_loss: 0.6453 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 10/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.5191 - accuracy: 0.8174\n",
            "Epoch 10: val_loss improved from 0.64526 to 0.59075, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 160s 108ms/step - loss: 0.5191 - accuracy: 0.8174 - val_loss: 0.5908 - val_accuracy: 0.7985 - lr: 1.0000e-04\n",
            "Epoch 11/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.4986 - accuracy: 0.8244\n",
            "Epoch 11: val_loss did not improve from 0.59075\n",
            "1480/1480 [==============================] - 158s 107ms/step - loss: 0.4986 - accuracy: 0.8244 - val_loss: 0.6007 - val_accuracy: 0.7890 - lr: 1.0000e-04\n",
            "Epoch 12/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.8344\n",
            "Epoch 12: val_loss improved from 0.59075 to 0.53838, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 161s 109ms/step - loss: 0.4688 - accuracy: 0.8344 - val_loss: 0.5384 - val_accuracy: 0.8154 - lr: 1.0000e-04\n",
            "Epoch 13/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.4431 - accuracy: 0.8434\n",
            "Epoch 13: val_loss improved from 0.53838 to 0.49951, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 164s 111ms/step - loss: 0.4431 - accuracy: 0.8434 - val_loss: 0.4995 - val_accuracy: 0.8259 - lr: 1.0000e-04\n",
            "Epoch 14/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.8472\n",
            "Epoch 14: val_loss improved from 0.49951 to 0.48731, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 165s 112ms/step - loss: 0.4311 - accuracy: 0.8472 - val_loss: 0.4873 - val_accuracy: 0.8293 - lr: 1.0000e-04\n",
            "Epoch 15/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.8552\n",
            "Epoch 15: val_loss improved from 0.48731 to 0.40647, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 164s 110ms/step - loss: 0.4091 - accuracy: 0.8552 - val_loss: 0.4065 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 16/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.8613\n",
            "Epoch 16: val_loss did not improve from 0.40647\n",
            "1480/1480 [==============================] - 164s 111ms/step - loss: 0.3981 - accuracy: 0.8613 - val_loss: 0.4198 - val_accuracy: 0.8538 - lr: 1.0000e-04\n",
            "Epoch 17/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.8683\n",
            "Epoch 17: val_loss improved from 0.40647 to 0.39700, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 165s 111ms/step - loss: 0.3793 - accuracy: 0.8683 - val_loss: 0.3970 - val_accuracy: 0.8638 - lr: 1.0000e-04\n",
            "Epoch 18/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.8702\n",
            "Epoch 18: val_loss did not improve from 0.39700\n",
            "1480/1480 [==============================] - 164s 111ms/step - loss: 0.3671 - accuracy: 0.8702 - val_loss: 0.4558 - val_accuracy: 0.8361 - lr: 1.0000e-04\n",
            "Epoch 19/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.8740\n",
            "Epoch 19: val_loss improved from 0.39700 to 0.38047, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 175s 119ms/step - loss: 0.3532 - accuracy: 0.8740 - val_loss: 0.3805 - val_accuracy: 0.8680 - lr: 1.0000e-04\n",
            "Epoch 20/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.8793\n",
            "Epoch 20: val_loss did not improve from 0.38047\n",
            "1480/1480 [==============================] - 160s 108ms/step - loss: 0.3391 - accuracy: 0.8793 - val_loss: 0.3858 - val_accuracy: 0.8650 - lr: 1.0000e-04\n",
            "Epoch 21/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.8794\n",
            "Epoch 21: val_loss improved from 0.38047 to 0.34052, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 162s 110ms/step - loss: 0.3410 - accuracy: 0.8794 - val_loss: 0.3405 - val_accuracy: 0.8857 - lr: 1.0000e-04\n",
            "Epoch 22/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.8842\n",
            "Epoch 22: val_loss did not improve from 0.34052\n",
            "1480/1480 [==============================] - 176s 119ms/step - loss: 0.3239 - accuracy: 0.8842 - val_loss: 0.3728 - val_accuracy: 0.8772 - lr: 1.0000e-04\n",
            "Epoch 23/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.8859\n",
            "Epoch 23: val_loss did not improve from 0.34052\n",
            "1480/1480 [==============================] - 162s 110ms/step - loss: 0.3208 - accuracy: 0.8859 - val_loss: 0.3972 - val_accuracy: 0.8546 - lr: 1.0000e-04\n",
            "Epoch 24/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.8906\n",
            "Epoch 24: val_loss improved from 0.34052 to 0.32095, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 163s 110ms/step - loss: 0.3038 - accuracy: 0.8906 - val_loss: 0.3209 - val_accuracy: 0.8883 - lr: 1.0000e-04\n",
            "Epoch 25/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.8933\n",
            "Epoch 25: val_loss did not improve from 0.32095\n",
            "1480/1480 [==============================] - 162s 109ms/step - loss: 0.2969 - accuracy: 0.8933 - val_loss: 0.3421 - val_accuracy: 0.8824 - lr: 1.0000e-04\n",
            "Epoch 26/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.8962\n",
            "Epoch 26: val_loss did not improve from 0.32095\n",
            "1480/1480 [==============================] - 174s 118ms/step - loss: 0.2927 - accuracy: 0.8962 - val_loss: 0.3246 - val_accuracy: 0.8856 - lr: 1.0000e-04\n",
            "Epoch 27/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.8981\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.32095\n",
            "1480/1480 [==============================] - 174s 117ms/step - loss: 0.2894 - accuracy: 0.8981 - val_loss: 0.3854 - val_accuracy: 0.8618 - lr: 1.0000e-04\n",
            "Epoch 28/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9139\n",
            "Epoch 28: val_loss improved from 0.32095 to 0.26027, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 174s 118ms/step - loss: 0.2322 - accuracy: 0.9139 - val_loss: 0.2603 - val_accuracy: 0.9058 - lr: 3.0000e-05\n",
            "Epoch 29/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9184\n",
            "Epoch 29: val_loss improved from 0.26027 to 0.24341, saving model to MidtermSkills.h5\n",
            "1480/1480 [==============================] - 162s 110ms/step - loss: 0.2224 - accuracy: 0.9184 - val_loss: 0.2434 - val_accuracy: 0.9136 - lr: 3.0000e-05\n",
            "Epoch 30/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9193\n",
            "Epoch 30: val_loss did not improve from 0.24341\n",
            "1480/1480 [==============================] - 176s 119ms/step - loss: 0.2179 - accuracy: 0.9193 - val_loss: 0.2807 - val_accuracy: 0.8984 - lr: 3.0000e-05\n",
            "Epoch 31/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9193\n",
            "Epoch 31: val_loss did not improve from 0.24341\n",
            "1480/1480 [==============================] - 155s 105ms/step - loss: 0.2175 - accuracy: 0.9193 - val_loss: 0.2524 - val_accuracy: 0.9106 - lr: 3.0000e-05\n",
            "Epoch 32/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.9221\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.24341\n",
            "1480/1480 [==============================] - 157s 106ms/step - loss: 0.2121 - accuracy: 0.9221 - val_loss: 0.2540 - val_accuracy: 0.9079 - lr: 3.0000e-05\n",
            "Epoch 33/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.1934 - accuracy: 0.9275\n",
            "Epoch 33: val_loss did not improve from 0.24341\n",
            "1480/1480 [==============================] - 157s 106ms/step - loss: 0.1934 - accuracy: 0.9275 - val_loss: 0.2557 - val_accuracy: 0.9079 - lr: 9.0000e-06\n",
            "Epoch 34/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9278\n",
            "Epoch 34: val_loss did not improve from 0.24341\n",
            "1480/1480 [==============================] - 158s 106ms/step - loss: 0.1904 - accuracy: 0.9278 - val_loss: 0.2547 - val_accuracy: 0.9064 - lr: 9.0000e-06\n",
            "Epoch 35/35\n",
            "1480/1480 [==============================] - ETA: 0s - loss: 0.1878 - accuracy: 0.9296\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.24341\n",
            "1480/1480 [==============================] - 159s 107ms/step - loss: 0.1878 - accuracy: 0.9296 - val_loss: 0.2520 - val_accuracy: 0.9113 - lr: 9.0000e-06\n"
          ]
        }
      ],
      "source": [
        "reduceLR = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    factor=0.3,\n",
        "    min_delta=0,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=(\"MidtermSkills.h5\"),\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs = 35,\n",
        "    validation_data = validation_gen,\n",
        "    callbacks=[reduceLR,checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGKkO7CHeTX5",
        "outputId": "d2d22a5e-1c4e-4bf2-bd1b-22657bb850e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 75, 75, 32)        1568      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 75, 75, 32)        16416     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 37, 37, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 37, 37, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 37, 37, 64)        32832     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 37, 37, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 37, 37, 64)        65600     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 37, 37, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 37, 37, 64)        65600     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 37, 37, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 18, 18, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 18, 18, 128)       131200    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 18, 18, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 18, 18, 128)       262272    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 18, 18, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 18, 18, 128)       262272    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 18, 18, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10368)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2654464   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 9)                 2313      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,560,329\n",
            "Trainable params: 3,560,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating the model of CNN+SOFTMAX model**"
      ],
      "metadata": {
        "id": "PfEYEUEnaBX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/My Datasets/1.h5')"
      ],
      "metadata": {
        "id": "gTwvndWXKLL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data, BATCH_SIZE, num_images):\n",
        "    data.reset()\n",
        "    X, y = data.next()\n",
        "    for i in tqdm.tqdm(range(int(num_images/BATCH_SIZE))):\n",
        "        img, label = data.next()\n",
        "        X = np.append(X, img, axis=0)\n",
        "        y = np.append(y, label, axis=0)\n",
        "        if i == int(num_images/BATCH_SIZE)-1:\n",
        "            break\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "\n",
        "num_test = 500\n",
        "X_test, y_test = create_dataset(test_gen, BATCH_SIZE, num_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTF4dWu8o32X",
        "outputId": "8590ad06-d4c5-4fa4-b54c-4b9b29d0024a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 14/15 [00:00<00:00, 41.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy score of train, validation, and valid**"
      ],
      "metadata": {
        "id": "Xwt9JLBPcwZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(train_gen)\n",
        "valid_loss, valid_acc = model.evaluate(validation_gen)\n",
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "\n",
        "print('Train Loss:', train_loss)\n",
        "print('Train Accuracy:', train_acc)\n",
        "print('Validation Loss:', valid_loss)\n",
        "print('Validation Accuracy:', valid_acc)\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "qzoPkvjpgnW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9f2db9-be29-4d43-b193-5d3b14190d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1480/1480 [==============================] - 154s 99ms/step - loss: 0.2402 - accuracy: 0.9130\n",
            "370/370 [==============================] - 35s 94ms/step - loss: 0.2532 - accuracy: 0.9087\n",
            "206/206 [==============================] - 8s 36ms/step - loss: 0.2879 - accuracy: 0.8954\n",
            "Train Loss: 0.24015335738658905\n",
            "Train Accuracy: 0.9130113124847412\n",
            "Validation Loss: 0.2531953752040863\n",
            "Validation Accuracy: 0.9087298512458801\n",
            "Test Loss: 0.28788307309150696\n",
            "Test Accuracy: 0.8953770995140076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification report**"
      ],
      "metadata": {
        "id": "526fFhmeePmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, np.rint(predicted)))"
      ],
      "metadata": {
        "id": "-7ib7-2zeWr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ec29f8-4f2f-44e1-d67c-f9c1a118f3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 17ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.61        37\n",
            "           1       0.97      0.65      0.78        55\n",
            "           2       0.94      0.96      0.95        46\n",
            "           3       0.97      0.97      0.97       105\n",
            "           4       1.00      0.82      0.90        49\n",
            "           5       0.98      0.92      0.95        50\n",
            "           6       0.95      1.00      0.97        70\n",
            "           7       0.67      0.72      0.70        54\n",
            "           8       0.98      0.98      0.98        46\n",
            "\n",
            "   micro avg       0.90      0.87      0.89       512\n",
            "   macro avg       0.90      0.85      0.87       512\n",
            "weighted avg       0.91      0.87      0.89       512\n",
            " samples avg       0.87      0.87      0.87       512\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC AUC CURVE**"
      ],
      "metadata": {
        "id": "aTMuYwfteSZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score,auc\n",
        "def plot_roc(y_test, y_pred_proba, model_name, dataset):\n",
        "    n_classes = y_test.shape[1]\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_proba[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred_proba.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    # Plot all ROC curves\n",
        "    plt.figure(figsize=(15,10))\n",
        "    plt.plot([0, 1], [0, 1], 'k--', linewidth=.5)\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "    plt.xlim([-0.01, 1.01])\n",
        "    plt.ylim([-0.01, 1.01])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {model_name} on {dataset}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_roc(y_test, predicted, \"CNN SOFTMAX MODEL\", \"Crop Plant Stress\")"
      ],
      "metadata": {
        "id": "YI8M5gUceUzW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "3b970405-b83d-4288-c705-68057e5e8ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "32GHdk_veXFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "df_cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(predicted, axis=1))\n",
        "\n",
        "\n",
        "ax = sns.heatmap(df_cm, annot=True, cmap='copper', fmt ='d')\n",
        "ax.set_title('\\nConfustion Matrix of CNN SOFTMAX', fontsize = 20);\n",
        "ax.set_xlabel('Predicted Values', fontsize = 15)\n",
        "ax.set_ylabel('Actual Values', fontsize = 15);\n",
        "\n",
        "plt.figure(figsize = (15,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ryL7fJAgebHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "ee47b647-a769-4aa8-b900-da7c5b756eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a model using SVM algorithm**"
      ],
      "metadata": {
        "id": "xcsFsrqRtbwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
      ],
      "metadata": {
        "id": "AuqDweZGkWI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "metadata": {
        "id": "nbf8oejG3vNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Splitting the train, validation, and test**"
      ],
      "metadata": {
        "id": "jOez0yiXacNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data, BATCH_SIZE, num_images):\n",
        "    data.reset()\n",
        "    X, y = data.next()\n",
        "    for i in tqdm.tqdm(range(int(num_images/BATCH_SIZE))):\n",
        "        img, label = data.next()\n",
        "        X = np.append(X, img, axis=0)\n",
        "        y = np.append(y, label, axis=0)\n",
        "        if i == int(num_images/BATCH_SIZE)-1:\n",
        "            break\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "num_train = 3000\n",
        "num_test = 500\n",
        "num_val = 900\n",
        "\n",
        "X_train, y_train = create_dataset(train_gen, BATCH_SIZE, num_train)\n",
        "X_val, y_val = create_dataset(validation_gen, BATCH_SIZE, num_val)\n",
        "X_test, y_test = create_dataset(test_gen, BATCH_SIZE, num_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06vtkpctXZBQ",
        "outputId": "4819de86-3fa9-4fbe-9f1c-cd91580ec002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 92/93 [00:18<00:00,  5.08it/s]\n",
            " 96%|█████████▋| 27/28 [00:01<00:00, 13.54it/s]\n",
            " 93%|█████████▎| 14/15 [00:00<00:00, 37.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.argmax(y_train, axis=1)\n",
        "y_val = np.argmax(y_val, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "id": "JqcG0VcmW0xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Features extraction of train, validation, and test**"
      ],
      "metadata": {
        "id": "wRGMvFhzaLJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_features = model.predict(X_train.reshape(-1, 75, 75, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0KpNGD4W5Me",
        "outputId": "45ca9926-accf-4bf8-fb3e-065553925ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 1s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tb569VEmOKd",
        "outputId": "aca34353-9c57-4841-aa12-110bf67c38ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.5049992e-10, 9.8322717e-10, 3.9545748e-17, ..., 1.0000000e+00,\n",
              "        1.4189675e-08, 3.7554709e-11],\n",
              "       [7.4934337e-06, 1.6882761e-04, 2.1187015e-08, ..., 2.4896875e-01,\n",
              "        7.9670521e-05, 1.4884483e-04],\n",
              "       [4.5379893e-06, 5.3034062e-09, 1.8949440e-06, ..., 6.4418265e-07,\n",
              "        7.5163189e-07, 3.5964653e-10],\n",
              "       ...,\n",
              "       [7.8195035e-01, 4.3949485e-03, 1.6757422e-04, ..., 1.9990806e-05,\n",
              "        2.1299526e-01, 1.0215745e-04],\n",
              "       [9.2336856e-04, 5.8598830e-03, 1.1715373e-05, ..., 9.2213690e-02,\n",
              "        5.9290705e-03, 2.0565826e-03],\n",
              "       [2.8901657e-03, 4.2406045e-02, 1.6256316e-01, ..., 2.3558494e-05,\n",
              "        1.8583886e-02, 8.5241807e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_features = model.predict(X_test.reshape(-1, 75, 75, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYUQzJOhYn4n",
        "outputId": "66cec195-86c5-45f2-c403-c1895c305bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX57JDOymPXB",
        "outputId": "403d34ad-ef34-4b9d-87ee-f8f7d5be774a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4073987e-01, 1.6428687e-04, 3.1308641e-04, ..., 4.6366054e-04,\n",
              "        7.1642429e-02, 5.2774056e-05],\n",
              "       [6.8761721e-02, 5.3622544e-01, 6.2697813e-02, ..., 2.4505600e-03,\n",
              "        1.9992310e-01, 1.3343862e-03],\n",
              "       [1.0760412e-04, 4.2427056e-03, 1.5167198e-05, ..., 5.4520783e-06,\n",
              "        9.3772570e-03, 3.8712515e-05],\n",
              "       ...,\n",
              "       [2.1191092e-06, 8.4366931e-08, 9.9998415e-01, ..., 1.1216331e-11,\n",
              "        5.4506228e-07, 5.7883270e-08],\n",
              "       [1.5959718e-05, 1.2359282e-08, 1.5983329e-05, ..., 1.8968556e-06,\n",
              "        2.3770829e-06, 7.5496462e-09],\n",
              "       [2.7497617e-05, 1.2336809e-09, 3.5739217e-06, ..., 1.0925296e-07,\n",
              "        1.0044896e-06, 2.8453273e-10]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_features = model.predict(X_val.reshape(-1, 75, 75, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pehH5d_eZzag",
        "outputId": "710027ea-08b9-470d-955c-856f420e559a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNaIj--WmQXA",
        "outputId": "534859b9-9f16-440f-a789-aff2dd1185df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.30694032e-01, 3.10104602e-04, 1.13323098e-03, ...,\n",
              "        4.35546172e-05, 2.85507739e-02, 8.36749375e-01],\n",
              "       [8.32268715e-01, 2.51614628e-03, 9.66658723e-03, ...,\n",
              "        2.22933618e-03, 7.53689259e-02, 1.33323791e-02],\n",
              "       [3.02239638e-02, 3.01440101e-04, 2.14794796e-04, ...,\n",
              "        1.35142063e-05, 1.29058007e-02, 9.53646362e-01],\n",
              "       ...,\n",
              "       [7.83854717e-11, 2.69133691e-11, 1.82307085e-20, ...,\n",
              "        1.00000000e+00, 5.66613823e-09, 6.03993851e-14],\n",
              "       [1.67037314e-07, 2.12751518e-04, 1.11546865e-11, ...,\n",
              "        1.67246224e-04, 1.84742948e-05, 5.21899119e-06],\n",
              "       [3.52301214e-07, 2.40526301e-08, 9.99994874e-01, ...,\n",
              "        1.26406557e-12, 1.23579218e-06, 7.15751511e-08]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using Gridsearch to find best parameters**"
      ],
      "metadata": {
        "id": "fI7vSZplalEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_SVC={'C': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 10.0],\n",
        "                'gamma': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
        "                'kernel': ['linear', 'rbf', 'polynomial']}\n",
        "\n",
        "SVC_cv=GridSearchCV(estimator=SVC(),\n",
        "                     param_grid = param_grid_SVC,\n",
        "                     scoring='accuracy',\n",
        "                     cv=10,\n",
        "                     refit=True,\n",
        "                     n_jobs=1)\n",
        "SVC_cv.fit(X_train_features,y_train)\n",
        "print(\"tuned hpyerparameters :(best parameters) \",SVC_cv.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLKHp0tbAmon",
        "outputId": "6770ff97-233d-4004-ec6f-ce2c01340a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tuned hpyerparameters :(best parameters)  {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVCmodel = SVC(C =10.0,\n",
        "               gamma = 0.001,\n",
        "               kernel = 'linear',\n",
        "               probability=True)"
      ],
      "metadata": {
        "id": "uKh8R_FarTCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVCmodel.fit(X_train_features,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "jgg4siXvr-UO",
        "outputId": "fed65b35-237f-4731-c51c-2a6b533e9ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10.0, gamma=0.001, kernel='linear', probability=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10.0, gamma=0.001, kernel=&#x27;linear&#x27;, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10.0, gamma=0.001, kernel=&#x27;linear&#x27;, probability=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = SVCmodel.predict(X_test_features)"
      ],
      "metadata": {
        "id": "MykcD4YDe28F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using Random Search to find best parameters**"
      ],
      "metadata": {
        "id": "GrlTEyIjbMiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_rand_SVC={'C': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 10.0],\n",
        "                'gamma': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
        "                'kernel': ['linear', 'rbf', 'polynomial']}\n",
        "\n",
        "SVC_cv3=RandomizedSearchCV(estimator=SVC(),\n",
        "                     param_distributions = param_rand_SVC,\n",
        "                     scoring='accuracy',\n",
        "                     cv=10,\n",
        "                     refit=True,\n",
        "                     n_jobs=1)\n",
        "SVC_cv3.fit(X_train_features,y_train)\n",
        "\n",
        "print(\"tuned hpyerparameters :(best parameters) \",SVC_cv3.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_q9tbgkbLyG",
        "outputId": "92ba9378-a554-4940-d5b1-653c2b7ec479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tuned hpyerparameters :(best parameters)  {'kernel': 'linear', 'gamma': 0.5, 'C': 10.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVCmodel1 = SVC(C =10.0,\n",
        "               gamma = 0.5,\n",
        "               kernel = 'linear',\n",
        "               probability=True)"
      ],
      "metadata": {
        "id": "J_ylYK_GtUCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVCmodel1.fit(X_train_features,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "jxdvZpFwtUCU",
        "outputId": "bb1f5269-d9d6-4ba0-f002-cc2da38a9f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10.0, gamma=0.5, kernel='linear', probability=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10.0, gamma=0.5, kernel=&#x27;linear&#x27;, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10.0, gamma=0.5, kernel=&#x27;linear&#x27;, probability=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1 = SVCmodel.predict(X_test_features)"
      ],
      "metadata": {
        "id": "HzB-dqq1tUCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating the model of CNN+SVM model**"
      ],
      "metadata": {
        "id": "hXtChNW6cLRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy score of train, validation, and valid**"
      ],
      "metadata": {
        "id": "xPkUXF9mc85u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "s8yJuiFMsZYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grid Search\n",
        "print(\"accuracy score of training :\",SVC_cv.best_score_)\n",
        "print(\"accuracy score of test :\",accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "zo7GYqODcKwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12fecb5a-afa3-4ad5-c205-a8dc1d48ff77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score of training : 0.9325105204872648\n",
            "accuracy score of test : 0.900390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Search\n",
        "print(\"accuracy score of training :\",SVC_cv3.best_score_)\n",
        "print(\"accuracy score of test :\",accuracy_score(y_test,y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qis9JK1xmlI3",
        "outputId": "f0dded91-796e-4529-ce76-71225596e59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score of training : 0.9358194905869324\n",
            "accuracy score of test : 0.900390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification report**"
      ],
      "metadata": {
        "id": "e7Ket8dmehdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"Classification report of CNN SVC with Grid Search\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "6yRcF1moehdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34b3c91-eaa1-4795-81ea-b55059ef46d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report of CNN SVC with Grid Search\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.57      0.68        47\n",
            "           1       0.88      0.73      0.80        48\n",
            "           2       0.96      0.96      0.96        56\n",
            "           3       0.96      0.97      0.97       110\n",
            "           4       0.96      0.88      0.92        59\n",
            "           5       0.98      0.96      0.97        48\n",
            "           6       0.97      1.00      0.98        56\n",
            "           7       0.59      0.91      0.72        46\n",
            "           8       1.00      1.00      1.00        42\n",
            "\n",
            "    accuracy                           0.90       512\n",
            "   macro avg       0.90      0.89      0.89       512\n",
            "weighted avg       0.91      0.90      0.90       512\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"Classification report of CNN SVC with Random Search\")\n",
        "print(classification_report(y_test, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83loucEnzMKV",
        "outputId": "c757015b-ee35-43b4-89d6-ecfdf5401521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report of CNN SVC with Random Search\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.57      0.68        47\n",
            "           1       0.88      0.73      0.80        48\n",
            "           2       0.96      0.96      0.96        56\n",
            "           3       0.96      0.97      0.97       110\n",
            "           4       0.96      0.88      0.92        59\n",
            "           5       0.98      0.96      0.97        48\n",
            "           6       0.97      1.00      0.98        56\n",
            "           7       0.59      0.91      0.72        46\n",
            "           8       1.00      1.00      1.00        42\n",
            "\n",
            "    accuracy                           0.90       512\n",
            "   macro avg       0.90      0.89      0.89       512\n",
            "weighted avg       0.91      0.90      0.90       512\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC AUC CURVE**"
      ],
      "metadata": {
        "id": "AMxnEPYUehdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "def plot_roc(y_true, y_proba, class_name):\n",
        "    fpr, tpr, thr = roc_curve(y_true, y_proba)\n",
        "    plt.plot(fpr, tpr, label='{} (AUC = {:.2f})'.format(class_name, roc_auc_score(y_true, y_proba)))\n",
        "    plt.plot([0, 1], [0, 1], 'k--', linewidth=.5)\n",
        "    plt.grid(True)\n",
        "    plt.xlim([-0.01, 1.01])\n",
        "    plt.ylim([-0.01, 1.01])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC AUC CURVE of CNN SVC with Grid Search')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "y_proba = SVCmodel.predict_proba(X_test_features)\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_proba, multi_class='ovr')))\n",
        "for i in range(9):\n",
        "    y_true_i = (y_test == i)\n",
        "    y_pred_i = y_proba[:, i]\n",
        "    plot_roc(y_true_i, y_pred_i, 'SVC Model + Grid Search {}'.format(i))"
      ],
      "metadata": {
        "id": "E07EzXWIehdw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "f2d1448f-57f8-490c-fe37-0729eadf9d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc-auc is 0.990\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "def plot_roc(y_true, y_proba, class_name):\n",
        "    fpr, tpr, thr = roc_curve(y_true, y_proba)\n",
        "    plt.plot(fpr, tpr, label='{} (AUC = {:.2f})'.format(class_name, roc_auc_score(y_true, y_proba)))\n",
        "    plt.plot([0, 1], [0, 1], 'k--', linewidth=.5)\n",
        "    plt.grid(True)\n",
        "    plt.xlim([-0.01, 1.01])\n",
        "    plt.ylim([-0.01, 1.01])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC AUC CURVE of CNN SVC with Grid Search')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "y_proba = SVCmodel1.predict_proba(X_test_features)\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_proba, multi_class='ovr')))\n",
        "for i in range(9):\n",
        "    y_true_i = (y_test == i)\n",
        "    y_pred_i = y_proba[:, i]\n",
        "    plot_roc(y_true_i, y_pred_i, 'SVC Model + Grid Search {}'.format(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "4fvO3oZXykaI",
        "outputId": "c9df48a6-af3a-4ec5-def4-c36c4af40eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc-auc is 0.990\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "XCBXI8lhehdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "df_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "ax = sns.heatmap(df_cm, annot=True, cmap='copper', fmt ='d')\n",
        "ax.set_title('\\nConfustion Matrix of CNN SVC with Grid Search', fontsize = 20);\n",
        "ax.set_xlabel('Predicted Values', fontsize = 15)\n",
        "ax.set_ylabel('Actual Values', fontsize = 15);\n",
        "\n",
        "plt.figure(figsize = (15,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sh0wmLtSehdw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "a21a30cb-bb06-4f53-edc8-3a3dc12ee7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "df_cm = confusion_matrix(y_test, y_pred1)\n",
        "\n",
        "ax = sns.heatmap(df_cm, annot=True, cmap='copper', fmt ='d')\n",
        "ax.set_title('\\nConfustion Matrix of CNN SVC with Random Search', fontsize = 20);\n",
        "ax.set_xlabel('Predicted Values', fontsize = 15)\n",
        "ax.set_ylabel('Actual Values', fontsize = 15);\n",
        "\n",
        "plt.figure(figsize = (15,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "nC_u4jvhzrZc",
        "outputId": "a25e2fbf-8762-4e68-eac4-93822c6ca6af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}